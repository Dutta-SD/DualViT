************************************************************************************************************************
Started at:  2023_09_23_16_32_42
TPVitImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x768])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TPTransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TPTransformerBlock(
        (mha): TPMHA(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (repr_layer): Linear(in_features=768, out_features=768, bias=True)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  tf-vit-single-model-p-16-224-from-scratch_1695466965
Starting Training...
Starting Train/Eval...
