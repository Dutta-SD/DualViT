# -*- coding: utf-8 -*-
"""ViTTests.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QBl3sduNhbxvuycxaeidXk3FowtuvL9s
"""

import os

import torch
import torch.nn as nn
import torchvision.transforms.transforms as tf


from pytorch_lightning import (
    LightningModule,
    Trainer,
    seed_everything,
    LightningDataModule,
)
from pytorch_lightning.callbacks import LearningRateMonitor
from pytorch_lightning.callbacks.progress import TQDMProgressBar
from pytorch_lightning.loggers import CSVLogger
from torch.optim.lr_scheduler import OneCycleLR
from torchmetrics.functional import accuracy
import warnings

warnings.filterwarnings("ignore")

seed_everything(7)

PATH_DATASETS = os.environ.get("PATH_DATASETS", "./data")
BATCH_SIZE = 32 if torch.cuda.is_available() else 4
NUM_WORKERS = int(os.cpu_count() / 2)

"""## Data Loader"""

from torchvision.datasets import CIFAR10
from typing import Any

IMG_SIZE = 224

train_transform = tf.Compose(
    [
        tf.PILToTensor(),
        # tf.AutoAugment(tf.AutoAugmentPolicy.CIFAR10),
        tf.Resize(IMG_SIZE, antialias=True),
        tf.RandomHorizontalFlip(0.5),
        tf.RandomVerticalFlip(0.5),
        # tf.RandomResizedCrop(),
        tf.ConvertImageDtype(torch.float32),
        tf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

test_transform = tf.Compose(
    [
        tf.PILToTensor(),
        tf.Resize(IMG_SIZE, antialias=True),
        tf.ConvertImageDtype(torch.float32),
        tf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)


class CIFAR10MultiLabelDataset(CIFAR10):
    def __init__(self, is_test: bool, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.fine_to_broad = [0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
        self.is_test = is_test

    def _broad(self, idx):
        return self.fine_to_broad[idx]

    def __len__(self):
        if self.is_test:
            return 8192 if self.train else 4096
        return super().__len__()

    def __getitem__(self, index: int) -> tuple[Any, Any, int | list[int]]:
        img_tensor, fine_label = super().__getitem__(index)
        return img_tensor, fine_label, self._broad(fine_label)


class CIFAR10MultiLabelDataModule(LightningDataModule):
    def __init__(
        self,
        is_test,
        train_transform,
        val_transform,
    ):
        super().__init__()
        self.is_test = is_test
        self.train_transform = train_transform
        self.val_transform = val_transform
        self.data_dir = PATH_DATASETS
        self.batch_size = BATCH_SIZE
        self.num_workers = NUM_WORKERS

    def prepare_data(self):
        # Download data
        CIFAR10MultiLabelDataset(
            self.is_test, root=self.data_dir, train=True, download=True
        )
        CIFAR10MultiLabelDataset(
            self.is_test, root=self.data_dir, train=False, download=True
        )

    def setup(self, stage=None):
        if stage == "fit" or stage is None:
            self.train_dset = CIFAR10MultiLabelDataset(
                self.is_test,
                root=self.data_dir,
                train=True,
                transform=self.train_transform,
            )
            self.val_dset = CIFAR10MultiLabelDataset(
                self.is_test,
                root=self.data_dir,
                train=False,
                transform=self.val_transform,
            )

    def train_dataloader(self):
        return torch.utils.data.DataLoader(
            self.train_dset,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            pin_memory=True,
        )

    def val_dataloader(self):
        return torch.utils.data.DataLoader(
            self.val_dset,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            pin_memory=True,
        )


cifar10_dm = CIFAR10MultiLabelDataModule(
    is_test=False,
    train_transform=train_transform,
    val_transform=test_transform,
)

cifar10_dm.prepare_data()
cifar10_dm.setup()

"""## Embedding Loss"""

from enum import Enum
import einops
import torch
from torch import nn


class BELMode(Enum):
    CLUSTER: str = "cluster"
    M3M: str = "m3m"


class BroadFineEmbeddingLoss(nn.Module):
    """
    Broad Fine Embedding Loss
    """

    def __init__(self, num_broad_classes, norm_order: int = 1) -> None:
        super().__init__()
        self.num_broad_classes = num_broad_classes
        self.norm_order = norm_order

    def broad_criterion(self, broad_mean, fine_mean):
        return torch.linalg.norm(broad_mean - fine_mean, self.norm_order)

    def adjust_class_token_shape(self, x):
        if isinstance(x, (list, tuple)):
            x = x[0]

        if len(x.shape) == 3:
            # B 1 D -> B D
            return x.squeeze(1)
        return x

    def _mean(self, x):
        return einops.reduce(x, "b d ->  1 d", "mean")

    def get_m3m_loss(self, broad_mean, fine_this_idx):
        # Mean v/s Mean of Means
        # [1, D] for all index -> [Z, D]
        fine_mean = torch.mean(torch.cat(fine_this_idx, dim=0), 0)
        return self.broad_criterion(broad_mean, fine_mean)

    def get_cluster_loss(self, broad_mean, fine_this_idx):
        # Cluster like loss, mu_center - x_i for all i
        # [1, D] for all index -> [Z, D]
        fine_mean = torch.cat(fine_this_idx, dim=0)
        return self.broad_criterion(broad_mean, fine_mean)

    def forward(
        self,
        broad_class_token,
        broad_labels,
        fine_class_token,
        fine_labels,
        mode: BELMode = BELMode.M3M,
    ) -> torch.Tensor:
        """Method to calculate Embedding Loss for Broad and Fine Labels

        Args:
            broad_class_token (torch.Tensor): Broad Class Embedding Token of shape [B, 1, D] or [B, D]
            broad_labels (torch.Tensor): Broad Class Labels of shape [B, ]
            fine_class_token (torch.Tensor): Fine Class Embedding Token of shape [B, 1, D] or [B, D]
            fine_labels (torch.Tensor): Fine Class Labels of shape [B, ]
            mode (BELMode): Mode of Final loss reduction, Cluster/M3M

        Returns:
            list[(torch.Tensor)]: List of embedding losses for each broad class present
        """
        embedding_losses = []
        # [B, D] dimensional tensor ensured for all class tokens
        broad_class_token = self.adjust_class_token_shape(broad_class_token)
        fine_class_token = self.adjust_class_token_shape(fine_class_token)

        for broad_idx in range(self.num_broad_classes):
            broad_label_filter = broad_labels == broad_idx
            fine_indexes = torch.unique(fine_labels[broad_label_filter])

            if len(fine_indexes) == 0:
                # If no fine labels corresponding to broad label, Empty, then no loss
                continue

            # [1, D]
            broad_mean = self._mean(broad_class_token[broad_label_filter])

            # All Elements of shape [1, D]
            fine_this_idx = [
                self._mean(fine_class_token[(fine_labels == fine_idx)])
                for fine_idx in fine_indexes
            ]

            # Loss as per modes
            if mode == BELMode.M3M:
                idx_loss = self.get_m3m_loss(broad_mean, fine_this_idx)
            elif mode == BELMode.CLUSTER:
                idx_loss = self.get_cluster_loss(broad_mean, fine_this_idx)

            embedding_losses.append(idx_loss)
        return embedding_losses


# broad_class_token = torch.rand(32, 768)
# broad_labels = torch.randint(0, 2, (32,))

# fine_class_token = torch.rand(32, 768)
# fine_labels = torch.randint(0, 10, (32,))

# loss = BroadFineEmbeddingLoss(num_broad_classes=2)

# # Sanity test
# loss(
#     broad_class_token,
#     broad_labels,
#     fine_class_token,
#     fine_labels,
#     mode=BELMode.CLUSTER
# )

import torch
from torch import nn
from transformers import ViTModel, ViTConfig


class SplitHierarchicalTPViT(ViTModel):
    def __init__(
        self, config: ViTConfig, num_broad_outputs: int = 2, num_fine_outputs: int = 10
    ):
        super().__init__(config)
        # Make sure number of hidden layers is even number
        self.n_broad = config.num_hidden_layers // 2
        del self.pooler
        self.classifier_fine = nn.Linear(
            config.hidden_size, num_fine_outputs, bias=True
        )
        self.classifier_broad = nn.Linear(
            config.hidden_size, num_broad_outputs, bias=True
        )

    def forward(self, pixel_values: torch.Tensor):
        ip_fine = ip_broad = self.embeddings(pixel_values)

        # Last ones are Layers, not list of layers
        broad_modules, last_broad_module = (
            self.encoder.layer[: self.n_broad - 1],
            self.encoder.layer[self.n_broad - 1],
        )
        fine_modules, last_fine_module = (
            self.encoder.layer[self.n_broad : -1],
            self.encoder.layer[-1],
        )

        for broad_module, fine_module in zip(broad_modules, fine_modules):
            # self.n_broad - 1 and last(-1) not used in TP
            output_broad = broad_module(ip_broad)[0]
            output_fine = fine_module(ip_fine)[0]
            ip_fine = output_fine * output_broad
            ip_broad = output_broad

        # output from last encoder layer without TP
        ip_broad = last_broad_module(ip_broad)[0]
        ip_fine = last_fine_module(ip_fine)[0]

        broad_embedding = ip_broad[:, :1, :]
        fine_embedding = ip_fine[:, :1, :]

        fine_logits = self.classify_fine(fine_embedding.squeeze(1))
        broad_logits = self.classify_broad(broad_embedding.squeeze(1))

        # [B, 1, D], [B, 1, D], [B, C_broad], [B, C_fine]
        return broad_embedding, fine_embedding, broad_logits, fine_logits

    def classify_fine(self, embeddings):
        return self.classifier_fine(embeddings)

    def classify_broad(self, embeddings):
        return self.classifier_broad(embeddings)


class SplitVitModule(LightningModule):
    def __init__(self, lr=0.05):
        super().__init__()

        self.save_hyperparameters()
        self.model = SplitHierarchicalTPViT(
            ViTConfig(), num_broad_outputs=2, num_fine_outputs=10
        )
        self.ce_loss = nn.CrossEntropyLoss()
        self.emb_loss = BroadFineEmbeddingLoss(num_broad_classes=2)

    def forward(self, x):
        return self.model(x)

    # def backward(self, loss):
    #     loss_emb, loss_broad_ce, loss_fine_ce = loss
    #     loss_broad_ce.backward(retain_graph=True)
    #     loss_fine_ce.backward(retain_graph=True)
    #     loss_emb.backward()

    def training_step(self, batch, batch_idx):
        # [B, 1, D], [B, 1, D], [B, C_broad], [B, C_fine]
        pixel_values, fine_labels, broad_labels = batch
        broad_embedding, fine_embedding, broad_logits, fine_logits = self(pixel_values)

        if (self.current_epoch + 1) % 2 == 0:
            # Broad Train
            fine_embedding = fine_embedding.clone().detach()
            loss_emb = torch.sum(
                torch.stack(
                    self.emb_loss(
                        broad_embedding, broad_labels, fine_embedding, fine_labels
                    )
                )
            )
            scale = 500
        else:
            # Fine Train With Scaling
            broad_embedding = broad_embedding.clone().detach()
            loss_emb = torch.sum(
                torch.stack(
                    self.emb_loss(
                        broad_embedding, broad_labels, fine_embedding, fine_labels
                    )
                )
            )
            scale = 10

        loss_emb = loss_emb / scale

        loss_broad_ce = self.ce_loss(broad_logits, broad_labels)
        loss_fine_ce = self.ce_loss(fine_logits, fine_labels)

        self.log("train_loss_emb", loss_emb)
        self.log("train_loss_fine_ce", loss_fine_ce)
        self.log("train_loss_broad_ce", loss_broad_ce)

        return loss_emb + loss_broad_ce + loss_fine_ce

    def evaluate(self, batch, stage=None):
        # [B, 1, D], [B, 1, D], [B, C_broad], [B, C_fine]
        pixel_values, fine_labels, broad_labels = batch
        broad_embedding, fine_embedding, broad_logits, fine_logits = self(pixel_values)

        loss_emb = torch.sum(
            torch.stack(
                self.emb_loss(
                    broad_embedding, broad_labels, fine_embedding, fine_labels
                )
            )
        )
        loss_broad_ce = self.ce_loss(broad_logits, broad_labels)
        loss_fine_ce = self.ce_loss(fine_logits, fine_labels)

        # Broad Class
        preds = torch.argmax(broad_logits, dim=1)
        acc_broad = accuracy(preds, broad_labels, task="binary")

        # Fine Class
        preds = torch.argmax(fine_logits, dim=1)
        acc_fine = accuracy(preds, fine_labels, task="multiclass", num_classes=10)

        if stage:
            self.log(f"{stage}_loss_fine", loss_fine_ce, prog_bar=True)
            self.log(f"{stage}_acc_fine", acc_fine, prog_bar=True)
            self.log(f"{stage}_loss_broad", loss_broad_ce, prog_bar=True)
            self.log(f"{stage}_acc_broad", acc_broad, prog_bar=True)
            self.log(f"{stage}_loss_emb", loss_emb, prog_bar=True)

    def validation_step(self, batch, batch_idx):
        self.evaluate(batch, "val")

    def test_step(self, batch, batch_idx):
        self.evaluate(batch, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.SGD(
            self.parameters(),
            lr=self.hparams.lr,
            momentum=0.9,
            weight_decay=1e-5,
        )
        steps_per_epoch = 45000 // BATCH_SIZE
        scheduler_dict = {
            "scheduler": OneCycleLR(
                optimizer,
                0.01,
                epochs=self.trainer.max_epochs,
                steps_per_epoch=steps_per_epoch,
            ),
            "interval": "step",
        }
        return {"optimizer": optimizer, "lr_scheduler": scheduler_dict}


model = SplitVitModule(lr=1e-3)

trainer = Trainer(
    max_epochs=30,
    accelerator="auto",
    devices=1,  # limiting got iPython runs
    logger=CSVLogger(save_dir="logs/"),
    callbacks=[
        LearningRateMonitor(logging_interval="step"),
        TQDMProgressBar(refresh_rate=10),
    ],
    num_sanity_val_steps=1,
    gradient_clip_val=0.5,
)

trainer.fit(model, cifar10_dm)

# trainer.test(model, datamodule=cifar10_dm)
