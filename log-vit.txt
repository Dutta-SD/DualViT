****************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
torch.Size([32, 10])
Last Saved Model Validation Accuracy: -1
****************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
torch.Size([32, 10])
Last Saved Model Validation Accuracy: -1
****************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
torch.Size([32, 10])
Last Saved Model Validation Accuracy: -1
****************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
torch.Size([32, 10])
Last Saved Model Validation Accuracy: -1
****************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
torch.Size([32, 10])
Last Saved Model Validation Accuracy: -1
torch.Size([128])
****************************************************************************************************
Exp: 2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 384, kernel_size=(2, 2), stride=(2, 2))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x1x384])
  (mlp_heads): ModuleList(
    (0): Linear(in_features=384, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-6): 7 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=384, out_features=384, bias=True)
          (key_layer): Linear(in_features=384, out_features=384, bias=True)
          (value_layer): Linear(in_features=384, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=384, out_features=384, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=384, out_features=384, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
)
Last Saved Model Validation Accuracy: -1


            Epoch: 0    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 2.04215
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.69819 Accuracy: 0.35400
            Best Accuracy till now: -1.00000
            
val_acc_fine Accuracy increased: -1.00000 -> 0.35400
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 1    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.77190
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.51377 Accuracy: 0.43252
            Best Accuracy till now: 0.35400
            
val_acc_fine Accuracy increased: 0.35400 -> 0.43252
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 2    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.61667
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.38943 Accuracy: 0.47998
            Best Accuracy till now: 0.43252
            
val_acc_fine Accuracy increased: 0.43252 -> 0.47998
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 3    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.47843
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.22786 Accuracy: 0.55820
            Best Accuracy till now: 0.47998
            
val_acc_fine Accuracy increased: 0.47998 -> 0.55820
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 4    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.37067
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.15929 Accuracy: 0.57676
            Best Accuracy till now: 0.55820
            
val_acc_fine Accuracy increased: 0.55820 -> 0.57676
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 5    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.50534
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.31860 Accuracy: 0.53818
            Best Accuracy till now: 0.57676
            


            Epoch: 6    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.44061
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.22693 Accuracy: 0.55820
            Best Accuracy till now: 0.57676
            


            Epoch: 7    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.35389
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.11551 Accuracy: 0.59404
            Best Accuracy till now: 0.57676
            
val_acc_fine Accuracy increased: 0.57676 -> 0.59404
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 8    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.26746
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.04555 Accuracy: 0.62500
            Best Accuracy till now: 0.59404
            
val_acc_fine Accuracy increased: 0.59404 -> 0.62500
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 9    

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.18763
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.97372 Accuracy: 0.65430
            Best Accuracy till now: 0.62500
            
val_acc_fine Accuracy increased: 0.62500 -> 0.65430
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 10   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.33670
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.11125 Accuracy: 0.60029
            Best Accuracy till now: 0.65430
            


            Epoch: 11   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.29035
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.05234 Accuracy: 0.61768
            Best Accuracy till now: 0.65430
            


            Epoch: 12   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.22593
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.04606 Accuracy: 0.62510
            Best Accuracy till now: 0.65430
            


            Epoch: 13   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.14694
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.93321 Accuracy: 0.66670
            Best Accuracy till now: 0.65430
            
val_acc_fine Accuracy increased: 0.65430 -> 0.66670
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 14   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.07311
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88689 Accuracy: 0.68379
            Best Accuracy till now: 0.66670
            
val_acc_fine Accuracy increased: 0.66670 -> 0.68379
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 15   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.23202
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 1.02301 Accuracy: 0.63955
            Best Accuracy till now: 0.68379
            


            Epoch: 16   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.19614
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.97118 Accuracy: 0.64473
            Best Accuracy till now: 0.68379
            


            Epoch: 17   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.13044
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92371 Accuracy: 0.66641
            Best Accuracy till now: 0.68379
            


            Epoch: 18   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.05407
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85953 Accuracy: 0.69229
            Best Accuracy till now: 0.68379
            
val_acc_fine Accuracy increased: 0.68379 -> 0.69229
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 19   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.98241
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83588 Accuracy: 0.70898
            Best Accuracy till now: 0.69229
            
val_acc_fine Accuracy increased: 0.69229 -> 0.70898
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 20   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.15064
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.97406 Accuracy: 0.65469
            Best Accuracy till now: 0.70898
            


            Epoch: 21   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.11734
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88893 Accuracy: 0.68018
            Best Accuracy till now: 0.70898
            


            Epoch: 22   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.05496
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88585 Accuracy: 0.68232
            Best Accuracy till now: 0.70898
            


            Epoch: 23   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.98602
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.80578 Accuracy: 0.71416
            Best Accuracy till now: 0.70898
            
val_acc_fine Accuracy increased: 0.70898 -> 0.71416
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 24   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.91026
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77443 Accuracy: 0.72734
            Best Accuracy till now: 0.71416
            
val_acc_fine Accuracy increased: 0.71416 -> 0.72734
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 25   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.08768
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88805 Accuracy: 0.68613
            Best Accuracy till now: 0.72734
            


            Epoch: 26   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.05814
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88568 Accuracy: 0.68525
            Best Accuracy till now: 0.72734
            


            Epoch: 27   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.00186
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83645 Accuracy: 0.69854
            Best Accuracy till now: 0.72734
            


            Epoch: 28   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.92210
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.80648 Accuracy: 0.71172
            Best Accuracy till now: 0.72734
            


            Epoch: 29   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.85432
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74390 Accuracy: 0.73350
            Best Accuracy till now: 0.72734
            
val_acc_fine Accuracy increased: 0.72734 -> 0.73350
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 30   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.03537
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87775 Accuracy: 0.68662
            Best Accuracy till now: 0.73350
            


            Epoch: 31   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 1.01121
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82553 Accuracy: 0.70469
            Best Accuracy till now: 0.73350
            


            Epoch: 32   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.94882
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78385 Accuracy: 0.72188
            Best Accuracy till now: 0.73350
            


            Epoch: 33   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.87174
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75325 Accuracy: 0.73369
            Best Accuracy till now: 0.73350
            
val_acc_fine Accuracy increased: 0.73350 -> 0.73369
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 34   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.79807
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73990 Accuracy: 0.74219
            Best Accuracy till now: 0.73369
            
val_acc_fine Accuracy increased: 0.73369 -> 0.74219
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 35   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.99096
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81029 Accuracy: 0.71309
            Best Accuracy till now: 0.74219
            


            Epoch: 36   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.95621
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78477 Accuracy: 0.72188
            Best Accuracy till now: 0.74219
            


            Epoch: 37   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.91304
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79025 Accuracy: 0.71865
            Best Accuracy till now: 0.74219
            


            Epoch: 38   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.83256
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73059 Accuracy: 0.74482
            Best Accuracy till now: 0.74219
            
val_acc_fine Accuracy increased: 0.74219 -> 0.74482
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 39   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.76340
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.72009 Accuracy: 0.75322
            Best Accuracy till now: 0.74482
            
val_acc_fine Accuracy increased: 0.74482 -> 0.75322
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 40   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.94650
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79404 Accuracy: 0.72305
            Best Accuracy till now: 0.75322
            


            Epoch: 41   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.92016
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77278 Accuracy: 0.72881
            Best Accuracy till now: 0.75322
            


            Epoch: 42   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.86760
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76324 Accuracy: 0.73379
            Best Accuracy till now: 0.75322
            


            Epoch: 43   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.78948
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76022 Accuracy: 0.74219
            Best Accuracy till now: 0.75322
            


            Epoch: 44   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.71521
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.70764 Accuracy: 0.75615
            Best Accuracy till now: 0.75322
            
val_acc_fine Accuracy increased: 0.75322 -> 0.75615
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 45   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.90572
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79524 Accuracy: 0.71260
            Best Accuracy till now: 0.75615
            


            Epoch: 46   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.88732
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78267 Accuracy: 0.72754
            Best Accuracy till now: 0.75615
            


            Epoch: 47   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.82631
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78392 Accuracy: 0.73096
            Best Accuracy till now: 0.75615
            


            Epoch: 48   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.75393
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73990 Accuracy: 0.74619
            Best Accuracy till now: 0.75615
            


            Epoch: 49   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.67813
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.70566 Accuracy: 0.76719
            Best Accuracy till now: 0.75615
            
val_acc_fine Accuracy increased: 0.75615 -> 0.76719
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 50   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.87086
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75928 Accuracy: 0.73037
            Best Accuracy till now: 0.76719
            


            Epoch: 51   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.85702
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73697 Accuracy: 0.73838
            Best Accuracy till now: 0.76719
            


            Epoch: 52   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.80243
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.72462 Accuracy: 0.74619
            Best Accuracy till now: 0.76719
            


            Epoch: 53   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.71295
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74694 Accuracy: 0.74492
            Best Accuracy till now: 0.76719
            


            Epoch: 54   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.65541
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.68728 Accuracy: 0.76738
            Best Accuracy till now: 0.76719
            
val_acc_fine Accuracy increased: 0.76719 -> 0.76738
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 55   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.84499
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76375 Accuracy: 0.73271
            Best Accuracy till now: 0.76738
            


            Epoch: 56   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.81989
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74077 Accuracy: 0.74248
            Best Accuracy till now: 0.76738
            


            Epoch: 57   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.76503
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.72625 Accuracy: 0.75869
            Best Accuracy till now: 0.76738
            


            Epoch: 58   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.68962
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.70827 Accuracy: 0.75918
            Best Accuracy till now: 0.76738
            


            Epoch: 59   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.61868
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.71406 Accuracy: 0.76123
            Best Accuracy till now: 0.76738
            


            Epoch: 60   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.81323
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77739 Accuracy: 0.73174
            Best Accuracy till now: 0.76738
            


            Epoch: 61   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.79541
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76858 Accuracy: 0.73340
            Best Accuracy till now: 0.76738
            


            Epoch: 62   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.73851
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75027 Accuracy: 0.74805
            Best Accuracy till now: 0.76738
            


            Epoch: 63   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.65651
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.70500 Accuracy: 0.76719
            Best Accuracy till now: 0.76738
            


            Epoch: 64   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.58552
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.71369 Accuracy: 0.77109
            Best Accuracy till now: 0.76738
            
val_acc_fine Accuracy increased: 0.76738 -> 0.77109
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 65   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.77955
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77705 Accuracy: 0.73926
            Best Accuracy till now: 0.77109
            


            Epoch: 66   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.77461
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79164 Accuracy: 0.72861
            Best Accuracy till now: 0.77109
            


            Epoch: 67   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.71555
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75072 Accuracy: 0.75547
            Best Accuracy till now: 0.77109
            


            Epoch: 68   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.63494
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.72872 Accuracy: 0.76641
            Best Accuracy till now: 0.77109
            


            Epoch: 69   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.56431
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73631 Accuracy: 0.76475
            Best Accuracy till now: 0.77109
            


            Epoch: 70   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.76147
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.80793 Accuracy: 0.73486
            Best Accuracy till now: 0.77109
            


            Epoch: 71   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.74436
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75695 Accuracy: 0.74482
            Best Accuracy till now: 0.77109
            


            Epoch: 72   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.68612
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73603 Accuracy: 0.75928
            Best Accuracy till now: 0.77109
            


            Epoch: 73   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.60905
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.72459 Accuracy: 0.76680
            Best Accuracy till now: 0.77109
            


            Epoch: 74   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54114
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74347 Accuracy: 0.77041
            Best Accuracy till now: 0.77109
            


            Epoch: 75   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.73256
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79542 Accuracy: 0.73457
            Best Accuracy till now: 0.77109
            


            Epoch: 76   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.72069
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75135 Accuracy: 0.75430
            Best Accuracy till now: 0.77109
            


            Epoch: 77   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.66056
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76602 Accuracy: 0.75371
            Best Accuracy till now: 0.77109
            


            Epoch: 78   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.59414
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74396 Accuracy: 0.76396
            Best Accuracy till now: 0.77109
            


            Epoch: 79   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51857
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.73441 Accuracy: 0.77432
            Best Accuracy till now: 0.77109
            
val_acc_fine Accuracy increased: 0.77109 -> 0.77432
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 80   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.70920
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83586 Accuracy: 0.73027
            Best Accuracy till now: 0.77432
            


            Epoch: 81   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.70749
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77484 Accuracy: 0.75186
            Best Accuracy till now: 0.77432
            


            Epoch: 82   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.65332
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74508 Accuracy: 0.76016
            Best Accuracy till now: 0.77432
            


            Epoch: 83   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.56693
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75835 Accuracy: 0.75840
            Best Accuracy till now: 0.77432
            


            Epoch: 84   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.50163
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76454 Accuracy: 0.77490
            Best Accuracy till now: 0.77432
            
val_acc_fine Accuracy increased: 0.77432 -> 0.77490
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 85   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.69391
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88408 Accuracy: 0.72129
            Best Accuracy till now: 0.77490
            


            Epoch: 86   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.68356
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75843 Accuracy: 0.75615
            Best Accuracy till now: 0.77490
            


            Epoch: 87   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.62469
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77985 Accuracy: 0.76211
            Best Accuracy till now: 0.77490
            


            Epoch: 88   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54769
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76412 Accuracy: 0.76865
            Best Accuracy till now: 0.77490
            


            Epoch: 89   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48377
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.76479 Accuracy: 0.77617
            Best Accuracy till now: 0.77490
            
val_acc_fine Accuracy increased: 0.77490 -> 0.77617
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 90   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.68004
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.75370 Accuracy: 0.75488
            Best Accuracy till now: 0.77617
            


            Epoch: 91   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.66594
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84117 Accuracy: 0.73545
            Best Accuracy till now: 0.77617
            


            Epoch: 92   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.61291
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.77004 Accuracy: 0.76533
            Best Accuracy till now: 0.77617
            


            Epoch: 93   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.53041
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81817 Accuracy: 0.76309
            Best Accuracy till now: 0.77617
            


            Epoch: 94   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47550
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78383 Accuracy: 0.77256
            Best Accuracy till now: 0.77617
            


            Epoch: 95   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.65685
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81623 Accuracy: 0.74023
            Best Accuracy till now: 0.77617
            


            Epoch: 96   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.65432
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82900 Accuracy: 0.74697
            Best Accuracy till now: 0.77617
            


            Epoch: 97   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.59285
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.80410 Accuracy: 0.76045
            Best Accuracy till now: 0.77617
            


            Epoch: 98   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51865
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79684 Accuracy: 0.77168
            Best Accuracy till now: 0.77617
            


            Epoch: 99   

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46374
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79864 Accuracy: 0.77715
            Best Accuracy till now: 0.77617
            
val_acc_fine Accuracy increased: 0.77617 -> 0.77715
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 100  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.63510
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83071 Accuracy: 0.73760
            Best Accuracy till now: 0.77715
            


            Epoch: 101  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.63506
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85295 Accuracy: 0.75283
            Best Accuracy till now: 0.77715
            


            Epoch: 102  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.57654
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79413 Accuracy: 0.76543
            Best Accuracy till now: 0.77715
            


            Epoch: 103  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.50512
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81937 Accuracy: 0.76426
            Best Accuracy till now: 0.77715
            


            Epoch: 104  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45285
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78644 Accuracy: 0.77842
            Best Accuracy till now: 0.77715
            
val_acc_fine Accuracy increased: 0.77715 -> 0.77842
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 105  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.63359
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85110 Accuracy: 0.74189
            Best Accuracy till now: 0.77842
            


            Epoch: 106  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.62943
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.80390 Accuracy: 0.75879
            Best Accuracy till now: 0.77842
            


            Epoch: 107  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.56612
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.78620 Accuracy: 0.76533
            Best Accuracy till now: 0.77842
            


            Epoch: 108  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48808
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79739 Accuracy: 0.77490
            Best Accuracy till now: 0.77842
            


            Epoch: 109  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42844
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.79281 Accuracy: 0.78135
            Best Accuracy till now: 0.77842
            
val_acc_fine Accuracy increased: 0.77842 -> 0.78135
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 110  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.62021
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84488 Accuracy: 0.74912
            Best Accuracy till now: 0.78135
            


            Epoch: 111  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.60510
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81496 Accuracy: 0.75430
            Best Accuracy till now: 0.78135
            


            Epoch: 112  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54683
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81918 Accuracy: 0.76699
            Best Accuracy till now: 0.78135
            


            Epoch: 113  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48527
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82706 Accuracy: 0.77510
            Best Accuracy till now: 0.78135
            


            Epoch: 114  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42412
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82053 Accuracy: 0.77920
            Best Accuracy till now: 0.78135
            


            Epoch: 115  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.60942
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.74885 Accuracy: 0.76094
            Best Accuracy till now: 0.78135
            


            Epoch: 116  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.59902
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83600 Accuracy: 0.75273
            Best Accuracy till now: 0.78135
            


            Epoch: 117  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54363
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82339 Accuracy: 0.76338
            Best Accuracy till now: 0.78135
            


            Epoch: 118  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47147
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83198 Accuracy: 0.77520
            Best Accuracy till now: 0.78135
            


            Epoch: 119  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42087
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83836 Accuracy: 0.77607
            Best Accuracy till now: 0.78135
            


            Epoch: 120  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.59716
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84908 Accuracy: 0.74824
            Best Accuracy till now: 0.78135
            


            Epoch: 121  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.58865
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81640 Accuracy: 0.75937
            Best Accuracy till now: 0.78135
            


            Epoch: 122  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.53304
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83445 Accuracy: 0.75420
            Best Accuracy till now: 0.78135
            


            Epoch: 123  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45889
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85359 Accuracy: 0.77305
            Best Accuracy till now: 0.78135
            


            Epoch: 124  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41365
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82300 Accuracy: 0.77949
            Best Accuracy till now: 0.78135
            


            Epoch: 125  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.58561
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85782 Accuracy: 0.75596
            Best Accuracy till now: 0.78135
            


            Epoch: 126  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.57260
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83819 Accuracy: 0.76377
            Best Accuracy till now: 0.78135
            


            Epoch: 127  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51866
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82561 Accuracy: 0.76582
            Best Accuracy till now: 0.78135
            


            Epoch: 128  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45855
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83499 Accuracy: 0.78037
            Best Accuracy till now: 0.78135
            


            Epoch: 129  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40814
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81429 Accuracy: 0.78281
            Best Accuracy till now: 0.78135
            
val_acc_fine Accuracy increased: 0.78135 -> 0.78281
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 130  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.57064
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86619 Accuracy: 0.74971
            Best Accuracy till now: 0.78281
            


            Epoch: 131  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.56828
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87351 Accuracy: 0.75430
            Best Accuracy till now: 0.78281
            


            Epoch: 132  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51057
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85245 Accuracy: 0.76738
            Best Accuracy till now: 0.78281
            


            Epoch: 133  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44749
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85277 Accuracy: 0.77461
            Best Accuracy till now: 0.78281
            


            Epoch: 134  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39833
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83785 Accuracy: 0.78096
            Best Accuracy till now: 0.78281
            


            Epoch: 135  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.56732
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88190 Accuracy: 0.75918
            Best Accuracy till now: 0.78281
            


            Epoch: 136  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.55859
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87156 Accuracy: 0.74990
            Best Accuracy till now: 0.78281
            


            Epoch: 137  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49959
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84009 Accuracy: 0.76885
            Best Accuracy till now: 0.78281
            


            Epoch: 138  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43940
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84495 Accuracy: 0.77969
            Best Accuracy till now: 0.78281
            


            Epoch: 139  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39466
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83100 Accuracy: 0.78623
            Best Accuracy till now: 0.78281
            
val_acc_fine Accuracy increased: 0.78281 -> 0.78623
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 140  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.55945
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89723 Accuracy: 0.75605
            Best Accuracy till now: 0.78623
            


            Epoch: 141  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.55325
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85666 Accuracy: 0.75889
            Best Accuracy till now: 0.78623
            


            Epoch: 142  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49368
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88009 Accuracy: 0.76475
            Best Accuracy till now: 0.78623
            


            Epoch: 143  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43082
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82777 Accuracy: 0.78184
            Best Accuracy till now: 0.78623
            


            Epoch: 144  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39170
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84397 Accuracy: 0.78184
            Best Accuracy till now: 0.78623
            


            Epoch: 145  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54913
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92907 Accuracy: 0.74375
            Best Accuracy till now: 0.78623
            


            Epoch: 146  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54707
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92394 Accuracy: 0.74854
            Best Accuracy till now: 0.78623
            


            Epoch: 147  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48734
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85008 Accuracy: 0.77100
            Best Accuracy till now: 0.78623
            


            Epoch: 148  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42680
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85707 Accuracy: 0.77734
            Best Accuracy till now: 0.78623
            


            Epoch: 149  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38050
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84238 Accuracy: 0.78203
            Best Accuracy till now: 0.78623
            


            Epoch: 150  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.54092
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91017 Accuracy: 0.74912
            Best Accuracy till now: 0.78623
            


            Epoch: 151  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.53174
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88572 Accuracy: 0.75957
            Best Accuracy till now: 0.78623
            


            Epoch: 152  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48158
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87665 Accuracy: 0.77188
            Best Accuracy till now: 0.78623
            


            Epoch: 153  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42765
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86405 Accuracy: 0.78213
            Best Accuracy till now: 0.78623
            


            Epoch: 154  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37505
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86070 Accuracy: 0.78711
            Best Accuracy till now: 0.78623
            
val_acc_fine Accuracy increased: 0.78623 -> 0.78711
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 155  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.53350
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83736 Accuracy: 0.75957
            Best Accuracy till now: 0.78711
            


            Epoch: 156  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.52223
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86942 Accuracy: 0.75967
            Best Accuracy till now: 0.78711
            


            Epoch: 157  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47813
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84127 Accuracy: 0.77412
            Best Accuracy till now: 0.78711
            


            Epoch: 158  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41211
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86875 Accuracy: 0.77480
            Best Accuracy till now: 0.78711
            


            Epoch: 159  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.36774
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86307 Accuracy: 0.78037
            Best Accuracy till now: 0.78711
            


            Epoch: 160  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.52249
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81734 Accuracy: 0.76367
            Best Accuracy till now: 0.78711
            


            Epoch: 161  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.52900
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84481 Accuracy: 0.76396
            Best Accuracy till now: 0.78711
            


            Epoch: 162  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47340
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85442 Accuracy: 0.77129
            Best Accuracy till now: 0.78711
            


            Epoch: 163  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40994
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84644 Accuracy: 0.78262
            Best Accuracy till now: 0.78711
            


            Epoch: 164  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.36602
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85014 Accuracy: 0.78438
            Best Accuracy till now: 0.78711
            


            Epoch: 165  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51558
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87606 Accuracy: 0.75371
            Best Accuracy till now: 0.78711
            


            Epoch: 166  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51859
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89011 Accuracy: 0.76279
            Best Accuracy till now: 0.78711
            


            Epoch: 167  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46669
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85551 Accuracy: 0.77344
            Best Accuracy till now: 0.78711
            


            Epoch: 168  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40680
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88501 Accuracy: 0.78076
            Best Accuracy till now: 0.78711
            


            Epoch: 169  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.36631
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85915 Accuracy: 0.78076
            Best Accuracy till now: 0.78711
            


            Epoch: 170  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51357
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90041 Accuracy: 0.76289
            Best Accuracy till now: 0.78711
            


            Epoch: 171  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.51354
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82691 Accuracy: 0.76543
            Best Accuracy till now: 0.78711
            


            Epoch: 172  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45921
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86291 Accuracy: 0.77080
            Best Accuracy till now: 0.78711
            


            Epoch: 173  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40221
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87388 Accuracy: 0.78398
            Best Accuracy till now: 0.78711
            


            Epoch: 174  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35791
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85494 Accuracy: 0.78965
            Best Accuracy till now: 0.78711
            
val_acc_fine Accuracy increased: 0.78711 -> 0.78965
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 175  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.50979
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88008 Accuracy: 0.76074
            Best Accuracy till now: 0.78965
            


            Epoch: 176  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.50130
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89921 Accuracy: 0.75840
            Best Accuracy till now: 0.78965
            


            Epoch: 177  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45813
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89548 Accuracy: 0.77568
            Best Accuracy till now: 0.78965
            


            Epoch: 178  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39640
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87759 Accuracy: 0.78311
            Best Accuracy till now: 0.78965
            


            Epoch: 179  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35432
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89390 Accuracy: 0.78545
            Best Accuracy till now: 0.78965
            


            Epoch: 180  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.50847
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87378 Accuracy: 0.76133
            Best Accuracy till now: 0.78965
            


            Epoch: 181  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49861
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83597 Accuracy: 0.76465
            Best Accuracy till now: 0.78965
            


            Epoch: 182  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44759
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88512 Accuracy: 0.77539
            Best Accuracy till now: 0.78965
            


            Epoch: 183  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39050
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86441 Accuracy: 0.78760
            Best Accuracy till now: 0.78965
            


            Epoch: 184  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35939
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85113 Accuracy: 0.79248
            Best Accuracy till now: 0.78965
            
val_acc_fine Accuracy increased: 0.78965 -> 0.79248
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 185  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49190
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.82577 Accuracy: 0.75908
            Best Accuracy till now: 0.79248
            


            Epoch: 186  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49811
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89199 Accuracy: 0.76006
            Best Accuracy till now: 0.79248
            


            Epoch: 187  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44808
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83922 Accuracy: 0.77607
            Best Accuracy till now: 0.79248
            


            Epoch: 188  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38744
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.93630 Accuracy: 0.77334
            Best Accuracy till now: 0.79248
            


            Epoch: 189  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35663
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88908 Accuracy: 0.78594
            Best Accuracy till now: 0.79248
            


            Epoch: 190  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49540
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88212 Accuracy: 0.75713
            Best Accuracy till now: 0.79248
            


            Epoch: 191  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.49188
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.81763 Accuracy: 0.77285
            Best Accuracy till now: 0.79248
            


            Epoch: 192  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44422
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89423 Accuracy: 0.77363
            Best Accuracy till now: 0.79248
            


            Epoch: 193  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38766
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86407 Accuracy: 0.78379
            Best Accuracy till now: 0.79248
            


            Epoch: 194  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34846
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85933 Accuracy: 0.78975
            Best Accuracy till now: 0.79248
            


            Epoch: 195  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48968
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87018 Accuracy: 0.76348
            Best Accuracy till now: 0.79248
            


            Epoch: 196  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48859
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84326 Accuracy: 0.76797
            Best Accuracy till now: 0.79248
            


            Epoch: 197  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44247
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91707 Accuracy: 0.76094
            Best Accuracy till now: 0.79248
            


            Epoch: 198  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38300
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88805 Accuracy: 0.78203
            Best Accuracy till now: 0.79248
            


            Epoch: 199  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34556
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88402 Accuracy: 0.78760
            Best Accuracy till now: 0.79248
            


            Epoch: 200  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48081
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92194 Accuracy: 0.74873
            Best Accuracy till now: 0.79248
            


            Epoch: 201  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.48233
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85256 Accuracy: 0.77031
            Best Accuracy till now: 0.79248
            


            Epoch: 202  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43512
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87162 Accuracy: 0.77842
            Best Accuracy till now: 0.79248
            


            Epoch: 203  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37312
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88058 Accuracy: 0.78652
            Best Accuracy till now: 0.79248
            


            Epoch: 204  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34330
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86101 Accuracy: 0.79277
            Best Accuracy till now: 0.79248
            
val_acc_fine Accuracy increased: 0.79248 -> 0.79277
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 205  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47760
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90873 Accuracy: 0.76660
            Best Accuracy till now: 0.79277
            


            Epoch: 206  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47811
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86867 Accuracy: 0.77070
            Best Accuracy till now: 0.79277
            


            Epoch: 207  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44008
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87656 Accuracy: 0.77988
            Best Accuracy till now: 0.79277
            


            Epoch: 208  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38308
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89028 Accuracy: 0.78389
            Best Accuracy till now: 0.79277
            


            Epoch: 209  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33618
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88472 Accuracy: 0.79043
            Best Accuracy till now: 0.79277
            


            Epoch: 210  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47257
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84259 Accuracy: 0.76172
            Best Accuracy till now: 0.79277
            


            Epoch: 211  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47579
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92910 Accuracy: 0.75928
            Best Accuracy till now: 0.79277
            


            Epoch: 212  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42925
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89377 Accuracy: 0.77617
            Best Accuracy till now: 0.79277
            


            Epoch: 213  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37693
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88850 Accuracy: 0.77852
            Best Accuracy till now: 0.79277
            


            Epoch: 214  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33271
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87840 Accuracy: 0.78701
            Best Accuracy till now: 0.79277
            


            Epoch: 215  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47184
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90060 Accuracy: 0.75762
            Best Accuracy till now: 0.79277
            


            Epoch: 216  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47918
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.83950 Accuracy: 0.76357
            Best Accuracy till now: 0.79277
            


            Epoch: 217  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42294
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84010 Accuracy: 0.77852
            Best Accuracy till now: 0.79277
            


            Epoch: 218  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37349
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85419 Accuracy: 0.78750
            Best Accuracy till now: 0.79277
            


            Epoch: 219  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33557
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87707 Accuracy: 0.78828
            Best Accuracy till now: 0.79277
            


            Epoch: 220  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46324
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91079 Accuracy: 0.76045
            Best Accuracy till now: 0.79277
            


            Epoch: 221  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.47102
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86290 Accuracy: 0.77979
            Best Accuracy till now: 0.79277
            


            Epoch: 222  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42325
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.94104 Accuracy: 0.76602
            Best Accuracy till now: 0.79277
            


            Epoch: 223  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37385
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91544 Accuracy: 0.77881
            Best Accuracy till now: 0.79277
            


            Epoch: 224  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.32860
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87515 Accuracy: 0.78711
            Best Accuracy till now: 0.79277
            


            Epoch: 225  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46664
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87922 Accuracy: 0.76201
            Best Accuracy till now: 0.79277
            


            Epoch: 226  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46612
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.94027 Accuracy: 0.76045
            Best Accuracy till now: 0.79277
            


            Epoch: 227  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41379
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88289 Accuracy: 0.77539
            Best Accuracy till now: 0.79277
            


            Epoch: 228  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.37604
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89894 Accuracy: 0.78486
            Best Accuracy till now: 0.79277
            


            Epoch: 229  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.32800
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87418 Accuracy: 0.79092
            Best Accuracy till now: 0.79277
            


            Epoch: 230  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46126
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86818 Accuracy: 0.77510
            Best Accuracy till now: 0.79277
            


            Epoch: 231  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.46209
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89880 Accuracy: 0.77197
            Best Accuracy till now: 0.79277
            


            Epoch: 232  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41483
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87903 Accuracy: 0.78008
            Best Accuracy till now: 0.79277
            


            Epoch: 233  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35926
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87720 Accuracy: 0.78516
            Best Accuracy till now: 0.79277
            


            Epoch: 234  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.32700
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84414 Accuracy: 0.79434
            Best Accuracy till now: 0.79277
            
val_acc_fine Accuracy increased: 0.79277 -> 0.79434
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 235  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45522
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88983 Accuracy: 0.76357
            Best Accuracy till now: 0.79434
            


            Epoch: 236  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45354
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84721 Accuracy: 0.76855
            Best Accuracy till now: 0.79434
            


            Epoch: 237  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41856
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86450 Accuracy: 0.77607
            Best Accuracy till now: 0.79434
            


            Epoch: 238  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.36176
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89129 Accuracy: 0.78281
            Best Accuracy till now: 0.79434
            


            Epoch: 239  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31978
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85874 Accuracy: 0.79609
            Best Accuracy till now: 0.79434
            
val_acc_fine Accuracy increased: 0.79434 -> 0.79609
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 240  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45152
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91462 Accuracy: 0.75928
            Best Accuracy till now: 0.79609
            


            Epoch: 241  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45560
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89865 Accuracy: 0.76484
            Best Accuracy till now: 0.79609
            


            Epoch: 242  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.41143
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89346 Accuracy: 0.77393
            Best Accuracy till now: 0.79609
            


            Epoch: 243  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.36435
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87940 Accuracy: 0.78779
            Best Accuracy till now: 0.79609
            


            Epoch: 244  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.32487
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90853 Accuracy: 0.78535
            Best Accuracy till now: 0.79609
            


            Epoch: 245  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.45102
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91364 Accuracy: 0.76631
            Best Accuracy till now: 0.79609
            


            Epoch: 246  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44906
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87069 Accuracy: 0.76699
            Best Accuracy till now: 0.79609
            


            Epoch: 247  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40690
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90213 Accuracy: 0.77529
            Best Accuracy till now: 0.79609
            


            Epoch: 248  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35316
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84975 Accuracy: 0.78672
            Best Accuracy till now: 0.79609
            


            Epoch: 249  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.32189
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84669 Accuracy: 0.79561
            Best Accuracy till now: 0.79609
            


            Epoch: 250  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44698
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87723 Accuracy: 0.76689
            Best Accuracy till now: 0.79609
            


            Epoch: 251  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44406
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87238 Accuracy: 0.77227
            Best Accuracy till now: 0.79609
            


            Epoch: 252  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40275
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89945 Accuracy: 0.77617
            Best Accuracy till now: 0.79609
            


            Epoch: 253  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35867
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91368 Accuracy: 0.78184
            Best Accuracy till now: 0.79609
            


            Epoch: 254  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31679
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87370 Accuracy: 0.79199
            Best Accuracy till now: 0.79609
            


            Epoch: 255  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44328
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85653 Accuracy: 0.76543
            Best Accuracy till now: 0.79609
            


            Epoch: 256  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44443
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91554 Accuracy: 0.76885
            Best Accuracy till now: 0.79609
            


            Epoch: 257  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.40826
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.92423 Accuracy: 0.77051
            Best Accuracy till now: 0.79609
            


            Epoch: 258  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34538
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89014 Accuracy: 0.78281
            Best Accuracy till now: 0.79609
            


            Epoch: 259  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31749
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86947 Accuracy: 0.79307
            Best Accuracy till now: 0.79609
            


            Epoch: 260  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44230
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91391 Accuracy: 0.75801
            Best Accuracy till now: 0.79609
            


            Epoch: 261  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44127
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86694 Accuracy: 0.77393
            Best Accuracy till now: 0.79609
            


            Epoch: 262  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39599
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86321 Accuracy: 0.78203
            Best Accuracy till now: 0.79609
            


            Epoch: 263  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34540
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91491 Accuracy: 0.78701
            Best Accuracy till now: 0.79609
            


            Epoch: 264  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31951
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88223 Accuracy: 0.79043
            Best Accuracy till now: 0.79609
            


            Epoch: 265  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43335
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90381 Accuracy: 0.76104
            Best Accuracy till now: 0.79609
            


            Epoch: 266  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44231
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86183 Accuracy: 0.76543
            Best Accuracy till now: 0.79609
            


            Epoch: 267  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39506
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87985 Accuracy: 0.78213
            Best Accuracy till now: 0.79609
            


            Epoch: 268  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.35129
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87550 Accuracy: 0.78896
            Best Accuracy till now: 0.79609
            


            Epoch: 269  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31700
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90173 Accuracy: 0.79189
            Best Accuracy till now: 0.79609
            


            Epoch: 270  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44130
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.95201 Accuracy: 0.76523
            Best Accuracy till now: 0.79609
            


            Epoch: 271  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.44433
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85134 Accuracy: 0.77344
            Best Accuracy till now: 0.79609
            


            Epoch: 272  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39790
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91337 Accuracy: 0.77432
            Best Accuracy till now: 0.79609
            


            Epoch: 273  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34640
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87176 Accuracy: 0.78779
            Best Accuracy till now: 0.79609
            


            Epoch: 274  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31594
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87034 Accuracy: 0.79170
            Best Accuracy till now: 0.79609
            


            Epoch: 275  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43845
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.94965 Accuracy: 0.76084
            Best Accuracy till now: 0.79609
            


            Epoch: 276  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43209
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87086 Accuracy: 0.76826
            Best Accuracy till now: 0.79609
            


            Epoch: 277  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39218
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91941 Accuracy: 0.77432
            Best Accuracy till now: 0.79609
            


            Epoch: 278  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34531
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88638 Accuracy: 0.78555
            Best Accuracy till now: 0.79609
            


            Epoch: 279  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.31474
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87120 Accuracy: 0.79600
            Best Accuracy till now: 0.79609
            


            Epoch: 280  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43729
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85969 Accuracy: 0.76836
            Best Accuracy till now: 0.79609
            


            Epoch: 281  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43239
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84878 Accuracy: 0.78066
            Best Accuracy till now: 0.79609
            


            Epoch: 282  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38416
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91757 Accuracy: 0.77695
            Best Accuracy till now: 0.79609
            


            Epoch: 283  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33932
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88341 Accuracy: 0.79102
            Best Accuracy till now: 0.79609
            


            Epoch: 284  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.30594
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85059 Accuracy: 0.80010
            Best Accuracy till now: 0.79609
            
val_acc_fine Accuracy increased: 0.79609 -> 0.80010
Model Saved @ ./checkpoints/ViT-CIFAR-10-FINE_ONLY-ID-2023-08-26 22:42:01.264798-hparams-omihub-autoaugment-on-out-proj-included-full-cifar-train.pt


            Epoch: 285  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42992
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.84018 Accuracy: 0.76787
            Best Accuracy till now: 0.80010
            


            Epoch: 286  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42928
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89542 Accuracy: 0.77266
            Best Accuracy till now: 0.80010
            


            Epoch: 287  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38873
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85396 Accuracy: 0.79434
            Best Accuracy till now: 0.80010
            


            Epoch: 288  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.34586
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.85975 Accuracy: 0.78926
            Best Accuracy till now: 0.80010
            


            Epoch: 289  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.30150
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87946 Accuracy: 0.79004
            Best Accuracy till now: 0.80010
            


            Epoch: 290  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42205
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86723 Accuracy: 0.76953
            Best Accuracy till now: 0.80010
            


            Epoch: 291  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43017
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.90906 Accuracy: 0.76963
            Best Accuracy till now: 0.80010
            


            Epoch: 292  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.39112
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89372 Accuracy: 0.77402
            Best Accuracy till now: 0.80010
            


            Epoch: 293  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33624
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89462 Accuracy: 0.78770
            Best Accuracy till now: 0.80010
            


            Epoch: 294  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.30832
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.86782 Accuracy: 0.78975
            Best Accuracy till now: 0.80010
            


            Epoch: 295  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.43294
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.91279 Accuracy: 0.76709
            Best Accuracy till now: 0.80010
            


            Epoch: 296  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.42452
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89247 Accuracy: 0.77305
            Best Accuracy till now: 0.80010
            


            Epoch: 297  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.38414
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.88331 Accuracy: 0.78623
            Best Accuracy till now: 0.80010
            


            Epoch: 298  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.33790
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.87507 Accuracy: 0.78721
            Best Accuracy till now: 0.80010
            


            Epoch: 299  

            Training Broad Class Loss: 0.00000 Fine Class Loss: 0.30132
            Validation Broad Class Loss: 0.00000 Accuracy: 0.00000 Fine Class Loss: 0.89862 Accuracy: 0.79170
            Best Accuracy till now: 0.80010
            
************************************************************************************************************************
Exp: vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Starting Train/Eval...
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693129887
Starting Train/Eval...
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693129981
Starting Train/Eval...
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693133692
************************************************************************************************************************
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289684
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.6720523834228516
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 0.4312545955181122
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1

************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289713
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.6720523834228516
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 0.4312545955181122
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1

************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.6720523834228516
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 0.4312545955181122
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 3.62 s
Starting Epoch:  1

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.6976591944694519
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 1
Mode: MODE.EVAL
Losses: 0.8099979758262634
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 4.52 s
Starting Epoch:  2

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.6190200448036194
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 2
Mode: MODE.EVAL
Losses: 1.7653450965881348
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 4.23 s
Starting Epoch:  3

Epoch: 3
Mode: MODE.TRAIN
Losses: 2.6882543563842773
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 3
Mode: MODE.EVAL
Losses: 0.9739255905151367
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 4.03 s
Starting Epoch:  4

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.1097030639648438
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 4
Mode: MODE.EVAL
Losses: 0.18164698779582977
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 3.98 s
Starting Epoch:  5

Epoch: 5
Mode: MODE.TRAIN
Losses: 4.552126884460449
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 5
Mode: MODE.EVAL
Losses: 0.7945139408111572
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.35 s
Starting Epoch:  6

Epoch: 6
Mode: MODE.TRAIN
Losses: 0.1672625094652176
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 6
Mode: MODE.EVAL
Losses: 0.486064612865448
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.38 s
Starting Epoch:  7

Epoch: 7
Mode: MODE.TRAIN
Losses: 0.49544820189476013
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 7
Mode: MODE.EVAL
Losses: 0.4564593434333801
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.40 s
Starting Epoch:  8

Epoch: 8
Mode: MODE.TRAIN
Losses: 1.9429264068603516
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 8
Mode: MODE.EVAL
Losses: 0.956807553768158
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.66 s
Starting Epoch:  9

Epoch: 9
Mode: MODE.TRAIN
Losses: 0.02124464139342308
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 9
Mode: MODE.EVAL
Losses: 1.523476243019104
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.30 s
Starting Epoch:  10

Epoch: 10
Mode: MODE.TRAIN
Losses: 0.041226647794246674
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 10
Mode: MODE.EVAL
Losses: 2.595705986022949
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 2.30 s
Starting Epoch:  11

Epoch: 11
Mode: MODE.TRAIN
Losses: 0.017795158550143242
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 11
Mode: MODE.EVAL
Losses: 4.270811080932617
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 1.0

Epoch took 2.26 s
Starting Epoch:  12

Epoch: 12
Mode: MODE.TRAIN
Losses: 0.02731313183903694
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 12
Mode: MODE.EVAL
Losses: 0.14127382636070251
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 1.0

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693289760.pt
Epoch took 3.91 s
Starting Epoch:  13

Epoch: 13
Mode: MODE.TRAIN
Losses: 2.1155600547790527
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 13
Mode: MODE.EVAL
Losses: 0.8512569665908813
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 1.0

Epoch took 3.11 s
Starting Epoch:  14

Epoch: 14
Mode: MODE.TRAIN
Losses: 1.1722116470336914
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 14
Mode: MODE.EVAL
Losses: 0.9024093151092529
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 3.23 s
Starting Epoch:  15

Epoch: 15
Mode: MODE.TRAIN
Losses: 1.022033452987671
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 15
Mode: MODE.EVAL
Losses: 0.8122442364692688
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 3.15 s
Starting Epoch:  16

Epoch: 16
Mode: MODE.TRAIN
Losses: 0.3226180076599121
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 16
Mode: MODE.EVAL
Losses: 0.766576886177063
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 3.51 s
Starting Epoch:  17

Epoch: 17
Mode: MODE.TRAIN
Losses: 1.4581711292266846
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 17
Mode: MODE.EVAL
Losses: 1.0074654817581177
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 3.09 s
Starting Epoch:  18

Epoch: 18
Mode: MODE.TRAIN
Losses: 0.5772867202758789
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 18
Mode: MODE.EVAL
Losses: 2.5913610458374023
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 1.0

Epoch took 3.12 s
Starting Epoch:  19

Epoch: 19
Mode: MODE.TRAIN
Losses: 0.3281688690185547
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: -1


Epoch: 19
Mode: MODE.EVAL
Losses: 0.7193734049797058
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 1.0

Epoch took 3.10 s
Starting Epoch:  20

Epoch: 20
Mode: MODE.TRAIN
Losses: 2.1283175945281982
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 20
Mode: MODE.EVAL
Losses: 0.12308596074581146
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 1.0

************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.6720523834228516
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 0.4312545955181122
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: -1

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
Epoch took 6.88 s
Starting Epoch:  1

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.6976591944694519
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5


Epoch: 1
Mode: MODE.EVAL
Losses: 0.8099979758262634
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
Epoch took 6.40 s
Starting Epoch:  2

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.6190200448036194
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5


Epoch: 2
Mode: MODE.EVAL
Losses: 1.7653450965881348
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
Epoch took 6.44 s
Starting Epoch:  3

Epoch: 3
Mode: MODE.TRAIN
Losses: 2.6882543563842773
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5


Epoch: 3
Mode: MODE.EVAL
Losses: 0.9739255905151367
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
Epoch took 6.44 s
Starting Epoch:  4

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.1097030639648438
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.5


Epoch: 4
Mode: MODE.EVAL
Losses: 0.18164698779582977
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.5

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
Epoch took 6.32 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290021.pt
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696
Starting Broad Class Training...
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.5287976264953613
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 0.3233568072319031
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.03 s
Starting Epoch:  1

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.11701034009456635
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75


Epoch: 1
Mode: MODE.EVAL
Losses: 0.5599424839019775
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.28 s
Starting Epoch:  2

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.2388565093278885
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 1.0


Epoch: 2
Mode: MODE.EVAL
Losses: 1.464702844619751
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.88 s
Starting Epoch:  3

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.6282217502593994
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 3
Mode: MODE.EVAL
Losses: 1.7204482555389404
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.51 s
Starting Epoch:  4

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.7888553142547607
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 4
Mode: MODE.EVAL
Losses: 0.07976322621107101
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.55 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696
Starting Fine Class Training...
Starting Train/Eval...
Starting Epoch:  0

Epoch: 0
Mode: MODE.TRAIN
Losses: 2.6661911010742188
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1


Epoch: 0
Mode: MODE.EVAL
Losses: 2.3277149200439453
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.08 s
Starting Epoch:  1

Epoch: 1
Mode: MODE.TRAIN
Losses: 2.7399637699127197
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0


Epoch: 1
Mode: MODE.EVAL
Losses: 3.184570550918579
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.89 s
Starting Epoch:  2

Epoch: 2
Mode: MODE.TRAIN
Losses: 2.4664978981018066
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0


Epoch: 2
Mode: MODE.EVAL
Losses: 2.3888652324676514
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.0

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.87 s
Starting Epoch:  3

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.985965371131897
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.0


Epoch: 3
Mode: MODE.EVAL
Losses: 2.5990121364593506
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.25

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.69 s
Starting Epoch:  4

Epoch: 4
Mode: MODE.TRAIN
Losses: 2.7587084770202637
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.25


Epoch: 4
Mode: MODE.EVAL
Losses: 1.9468594789505005
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.25

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
Epoch took 5.63 s
Final Model saved @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693290696.pt
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.5287976264953613
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.75

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3233568072319031
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.75
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 8.20 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.11701034009456635
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Train Metrics increased from :0.75 -> 1.0

Epoch: 1
Mode: MODE.EVAL
Losses: 0.5599424839019775
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 0.75

Eval Metrics increased from :0.75 -> 0.75
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 8.76 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.2388565093278885
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 1.0


Epoch: 2
Mode: MODE.EVAL
Losses: 1.464702844619751
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 8.45 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.6282217502593994
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 3
Mode: MODE.EVAL
Losses: 1.7204482555389404
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.75

Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 9.89 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.7888553142547607
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 4
Mode: MODE.EVAL
Losses: 0.07976322621107101
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Eval Metrics increased from :0.75 -> 1.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 9.27 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 2.6661911010742188
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.0

Epoch: 0
Mode: MODE.EVAL
Losses: 2.3277149200439453
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 9.04 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 2.7399637699127197
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0

Train Metrics increased from :0.0 -> 0.0

Epoch: 1
Mode: MODE.EVAL
Losses: 3.184570550918579
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0

Eval Metrics increased from :0.0 -> 0.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291044.pt
Epoch took 9.46 s
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.FloatTensor of size 1x1x768]
      (1): Parameter containing: [torch.FloatTensor of size 1x1x768]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (3): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (6): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (7): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (8): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (9): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (10): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (11): TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU()
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.5287976264953613
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.75

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3233568072319031
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.75
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Epoch took 8.35 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.11701034009456635
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Train Metrics increased from :0.75 -> 1.0

Epoch: 1
Mode: MODE.EVAL
Losses: 0.5599424839019775
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 0.75

Epoch took 5.37 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.2388565093278885
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 1.0


Epoch: 2
Mode: MODE.EVAL
Losses: 1.464702844619751
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.75

Epoch took 5.36 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.6282217502593994
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 3
Mode: MODE.EVAL
Losses: 1.7204482555389404
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.75

Epoch took 5.60 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.7888553142547607
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 4
Mode: MODE.EVAL
Losses: 0.07976322621107101
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Eval Metrics increased from :0.75 -> 1.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Epoch took 9.20 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 2.6661911010742188
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.0

Epoch: 0
Mode: MODE.EVAL
Losses: 2.3277149200439453
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Epoch took 8.28 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 2.7399637699127197
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0


Epoch: 1
Mode: MODE.EVAL
Losses: 3.184570550918579
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0

Epoch took 5.58 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 2.4664978981018066
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: 0.0


Epoch: 2
Mode: MODE.EVAL
Losses: 2.3888652324676514
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.0

Eval Metrics increased from :0.0 -> 0.25
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Epoch took 9.07 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.985965371131897
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.0

Train Metrics increased from :0.0 -> 0.25

Epoch: 3
Mode: MODE.EVAL
Losses: 2.5990121364593506
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.25

Epoch took 5.98 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 2.7587084770202637
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.25


Epoch: 4
Mode: MODE.EVAL
Losses: 1.9468594789505005
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.25

Eval Metrics increased from :0.25 -> 0.5
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
Epoch took 9.04 s
Final Model saved @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291129.pt
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291616
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.5287978649139404
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.75

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3233562707901001
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.75
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291616.pt
Epoch took 3.57 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.11701051890850067
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Train Metrics increased from :0.75 -> 1.0

Epoch: 1
Mode: MODE.EVAL
Losses: 0.559942901134491
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 0.75

Epoch took 0.42 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.2388567179441452
Metrics: {'Acc@1': 0.75}
Best Acc@1 till now: 1.0


Epoch: 2
Mode: MODE.EVAL
Losses: 1.46470308303833
Metrics: {'Acc@1': 0.5}
Best Acc@1 till now: 0.75

Epoch took 0.42 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.6282216310501099
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 3
Mode: MODE.EVAL
Losses: 1.7204468250274658
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 0.75

Epoch took 0.38 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.7888548374176025
Metrics: {'Acc@1': 0.25}
Best Acc@1 till now: 1.0


Epoch: 4
Mode: MODE.EVAL
Losses: 0.07976318895816803
Metrics: {'Acc@1': 1.0}
Best Acc@1 till now: 0.75

Eval Metrics increased from :0.75 -> 1.0
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291616.pt
Epoch took 2.80 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291616.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291616
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 2.6661903858184814
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Train Metrics increased from :-1 -> 0.0

Epoch: 0
Mode: MODE.EVAL
Losses: 2.3277151584625244
Metrics: {'Acc@1': 0.0}
Best Acc@1 till now: -1

Eval Metrics increased from :-1 -> 0.0
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.4065633869879996
Metrics: {'Acc@1': 0.8161365}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.8161364793777466

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3490693208518302
Metrics: {'Acc@1': 0.85001993}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.8500199317932129
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
Epoch took 1012.67 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.34687449365778045
Metrics: {'Acc@1': 0.8485654}
Best Acc@1 till now: 0.8161364793777466

Train Metrics increased from: 0.8161364793777466 -> 0.848565399646759

Epoch: 1
Mode: MODE.EVAL
Losses: 0.3494789210284591
Metrics: {'Acc@1': 0.8485271}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.07 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.3278814739049853
Metrics: {'Acc@1': 0.85837597}
Best Acc@1 till now: 0.848565399646759

Train Metrics increased from: 0.848565399646759 -> 0.8583759665489197

Epoch: 2
Mode: MODE.EVAL
Losses: 0.40384280083665425
Metrics: {'Acc@1': 0.8205613}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1014.82 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 0.31358249325429083
Metrics: {'Acc@1': 0.8664082}
Best Acc@1 till now: 0.8583759665489197

Train Metrics increased from: 0.8583759665489197 -> 0.8664082288742065

Epoch: 3
Mode: MODE.EVAL
Losses: 0.4396715682403297
Metrics: {'Acc@1': 0.8016521}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.36 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 0.30268048403589315
Metrics: {'Acc@1': 0.87164325}
Best Acc@1 till now: 0.8664082288742065

Train Metrics increased from: 0.8664082288742065 -> 0.8716432452201843

Epoch: 4
Mode: MODE.EVAL
Losses: 0.3598057313519678
Metrics: {'Acc@1': 0.846039}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.11 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 1.8202311989596434
Metrics: {'Acc@1': 0.32324967}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.3232496678829193

Epoch: 0
Mode: MODE.EVAL
Losses: 1.7420862404404172
Metrics: {'Acc@1': 0.3482285}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.3482285141944885
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
Epoch took 1017.66 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 1.6373541803311205
Metrics: {'Acc@1': 0.39486092}
Best Acc@1 till now: 0.3232496678829193

Train Metrics increased from: 0.3232496678829193 -> 0.3948609232902527

Epoch: 1
Mode: MODE.EVAL
Losses: 1.6673660134054293
Metrics: {'Acc@1': 0.38554937}
Best Acc@1 till now: 0.3482285141944885

Eval Metrics increased from: 0.3482285141944885 -> 0.3855493664741516
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
Epoch took 1017.78 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 1.550424219702211
Metrics: {'Acc@1': 0.42996722}
Best Acc@1 till now: 0.3948609232902527

Train Metrics increased from: 0.3948609232902527 -> 0.4299672245979309

Epoch: 2
Mode: MODE.EVAL
Losses: 1.5419795627047301
Metrics: {'Acc@1': 0.44167992}
Best Acc@1 till now: 0.3855493664741516

Eval Metrics increased from: 0.3855493664741516 -> 0.4416799247264862
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
Epoch took 1017.58 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.480759515024512
Metrics: {'Acc@1': 0.46111733}
Best Acc@1 till now: 0.4299672245979309

Train Metrics increased from: 0.4299672245979309 -> 0.46111732721328735

Epoch: 3
Mode: MODE.EVAL
Losses: 1.5729291719995486
Metrics: {'Acc@1': 0.4116242}
Best Acc@1 till now: 0.4416799247264862

Epoch took 1014.92 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.4211319777971643
Metrics: {'Acc@1': 0.4831162}
Best Acc@1 till now: 0.46111732721328735

Train Metrics increased from: 0.46111732721328735 -> 0.4831162095069885

Epoch: 4
Mode: MODE.EVAL
Losses: 1.5639273414186612
Metrics: {'Acc@1': 0.4343153}
Best Acc@1 till now: 0.4416799247264862

Epoch took 1015.69 s
Final Model saved @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693291939.pt
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.4065633869879996
Metrics: {'Acc@1': 0.8161365}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.8161364793777466

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3490693208518302
Metrics: {'Acc@1': 0.85001993}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.8500199317932129
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1012.85 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.34687449365778045
Metrics: {'Acc@1': 0.8485654}
Best Acc@1 till now: 0.8161364793777466

Train Metrics increased from: 0.8161364793777466 -> 0.848565399646759

Epoch: 1
Mode: MODE.EVAL
Losses: 0.3494789210284591
Metrics: {'Acc@1': 0.8485271}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.03 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 0.3278814739049853
Metrics: {'Acc@1': 0.85837597}
Best Acc@1 till now: 0.848565399646759

Train Metrics increased from: 0.848565399646759 -> 0.8583759665489197

Epoch: 2
Mode: MODE.EVAL
Losses: 0.40384280083665425
Metrics: {'Acc@1': 0.8205613}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.16 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 0.31358249325429083
Metrics: {'Acc@1': 0.8664082}
Best Acc@1 till now: 0.8583759665489197

Train Metrics increased from: 0.8583759665489197 -> 0.8664082288742065

Epoch: 3
Mode: MODE.EVAL
Losses: 0.4396715682403297
Metrics: {'Acc@1': 0.8016521}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1015.10 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 0.30268048403589315
Metrics: {'Acc@1': 0.87164325}
Best Acc@1 till now: 0.8664082288742065

Train Metrics increased from: 0.8664082288742065 -> 0.8716432452201843

Epoch: 4
Mode: MODE.EVAL
Losses: 0.3598057313519678
Metrics: {'Acc@1': 0.846039}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1014.80 s

Epoch: 5
Mode: MODE.TRAIN
Losses: 0.29295653786958026
Metrics: {'Acc@1': 0.8756394}
Best Acc@1 till now: 0.8716432452201843

Train Metrics increased from: 0.8716432452201843 -> 0.8756393790245056

Epoch: 5
Mode: MODE.EVAL
Losses: 0.2931130237070618
Metrics: {'Acc@1': 0.8766919}
Best Acc@1 till now: 0.8500199317932129

Eval Metrics increased from: 0.8500199317932129 -> 0.8766918778419495
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.43 s

Epoch: 6
Mode: MODE.TRAIN
Losses: 0.2852394801786031
Metrics: {'Acc@1': 0.8796955}
Best Acc@1 till now: 0.8756393790245056

Train Metrics increased from: 0.8756393790245056 -> 0.879695475101471

Epoch: 6
Mode: MODE.EVAL
Losses: 0.299336921162666
Metrics: {'Acc@1': 0.87350714}
Best Acc@1 till now: 0.8766918778419495

Epoch took 1014.76 s

Epoch: 7
Mode: MODE.TRAIN
Losses: 0.277107739216074
Metrics: {'Acc@1': 0.88423115}
Best Acc@1 till now: 0.879695475101471

Train Metrics increased from: 0.879695475101471 -> 0.8842311501502991

Epoch: 7
Mode: MODE.EVAL
Losses: 0.27626446658258985
Metrics: {'Acc@1': 0.8846537}
Best Acc@1 till now: 0.8766918778419495

Eval Metrics increased from: 0.8766918778419495 -> 0.8846536874771118
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.60 s

Epoch: 8
Mode: MODE.TRAIN
Losses: 0.27337796211509446
Metrics: {'Acc@1': 0.8851902}
Best Acc@1 till now: 0.8842311501502991

Train Metrics increased from: 0.8842311501502991 -> 0.8851901888847351

Epoch: 8
Mode: MODE.EVAL
Losses: 0.27270936932723233
Metrics: {'Acc@1': 0.88495225}
Best Acc@1 till now: 0.8846536874771118

Eval Metrics increased from: 0.8846536874771118 -> 0.8849522471427917
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.93 s

Epoch: 9
Mode: MODE.TRAIN
Losses: 0.26698268060107977
Metrics: {'Acc@1': 0.88866687}
Best Acc@1 till now: 0.8851901888847351

Train Metrics increased from: 0.8851901888847351 -> 0.8886668682098389

Epoch: 9
Mode: MODE.EVAL
Losses: 0.31954826072902437
Metrics: {'Acc@1': 0.8618631}
Best Acc@1 till now: 0.8849522471427917

Epoch took 1014.83 s

Epoch: 10
Mode: MODE.TRAIN
Losses: 0.26306433800388784
Metrics: {'Acc@1': 0.8903253}
Best Acc@1 till now: 0.8886668682098389

Train Metrics increased from: 0.8886668682098389 -> 0.8903253078460693

Epoch: 10
Mode: MODE.EVAL
Losses: 0.30141285204204027
Metrics: {'Acc@1': 0.8740048}
Best Acc@1 till now: 0.8849522471427917

Epoch took 1015.37 s

Epoch: 11
Mode: MODE.TRAIN
Losses: 0.25806562635866576
Metrics: {'Acc@1': 0.892743}
Best Acc@1 till now: 0.8903253078460693

Train Metrics increased from: 0.8903253078460693 -> 0.8927429914474487

Epoch: 11
Mode: MODE.EVAL
Losses: 0.264743868712407
Metrics: {'Acc@1': 0.88803744}
Best Acc@1 till now: 0.8849522471427917

Eval Metrics increased from: 0.8849522471427917 -> 0.8880374431610107
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.68 s

Epoch: 12
Mode: MODE.TRAIN
Losses: 0.25395068611063615
Metrics: {'Acc@1': 0.8949009}
Best Acc@1 till now: 0.8927429914474487

Train Metrics increased from: 0.8927429914474487 -> 0.894900918006897

Epoch: 12
Mode: MODE.EVAL
Losses: 0.2775585618178556
Metrics: {'Acc@1': 0.88226515}
Best Acc@1 till now: 0.8880374431610107

Epoch took 1015.28 s

Epoch: 13
Mode: MODE.TRAIN
Losses: 0.2507904979979138
Metrics: {'Acc@1': 0.8969789}
Best Acc@1 till now: 0.894900918006897

Train Metrics increased from: 0.894900918006897 -> 0.8969789147377014

Epoch: 13
Mode: MODE.EVAL
Losses: 0.25348004034370375
Metrics: {'Acc@1': 0.89301354}
Best Acc@1 till now: 0.8880374431610107

Eval Metrics increased from: 0.8880374431610107 -> 0.8930135369300842
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.55 s

Epoch: 14
Mode: MODE.TRAIN
Losses: 0.2458599096121233
Metrics: {'Acc@1': 0.8988771}
Best Acc@1 till now: 0.8969789147377014

Train Metrics increased from: 0.8969789147377014 -> 0.8988770842552185

Epoch: 14
Mode: MODE.EVAL
Losses: 0.2608193447635432
Metrics: {'Acc@1': 0.8935112}
Best Acc@1 till now: 0.8930135369300842

Eval Metrics increased from: 0.8930135369300842 -> 0.893511176109314
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.29 s

Epoch: 15
Mode: MODE.TRAIN
Losses: 0.2431707108664848
Metrics: {'Acc@1': 0.9002158}
Best Acc@1 till now: 0.8988770842552185

Train Metrics increased from: 0.8988770842552185 -> 0.9002158045768738

Epoch: 15
Mode: MODE.EVAL
Losses: 0.24516049079644453
Metrics: {'Acc@1': 0.89759153}
Best Acc@1 till now: 0.893511176109314

Eval Metrics increased from: 0.893511176109314 -> 0.8975915312767029
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.71 s

Epoch: 16
Mode: MODE.TRAIN
Losses: 0.23821106158635197
Metrics: {'Acc@1': 0.9027733}
Best Acc@1 till now: 0.9002158045768738

Train Metrics increased from: 0.9002158045768738 -> 0.9027733206748962

Epoch: 16
Mode: MODE.EVAL
Losses: 0.28038517518597805
Metrics: {'Acc@1': 0.88365847}
Best Acc@1 till now: 0.8975915312767029

Epoch took 1014.78 s

Epoch: 17
Mode: MODE.TRAIN
Losses: 0.2374992278187781
Metrics: {'Acc@1': 0.90289325}
Best Acc@1 till now: 0.9027733206748962

Train Metrics increased from: 0.9027733206748962 -> 0.9028932452201843

Epoch: 17
Mode: MODE.EVAL
Losses: 0.28944530508890276
Metrics: {'Acc@1': 0.87758756}
Best Acc@1 till now: 0.8975915312767029

Epoch took 1015.07 s

Epoch: 18
Mode: MODE.TRAIN
Losses: 0.23337299986492338
Metrics: {'Acc@1': 0.9029732}
Best Acc@1 till now: 0.9028932452201843

Train Metrics increased from: 0.9028932452201843 -> 0.9029731750488281

Epoch: 18
Mode: MODE.EVAL
Losses: 0.2555893941479883
Metrics: {'Acc@1': 0.89440686}
Best Acc@1 till now: 0.8975915312767029

Epoch took 1014.92 s

Epoch: 19
Mode: MODE.TRAIN
Losses: 0.2304226988855073
Metrics: {'Acc@1': 0.90609014}
Best Acc@1 till now: 0.9029731750488281

Train Metrics increased from: 0.9029731750488281 -> 0.9060901403427124

Epoch: 19
Mode: MODE.EVAL
Losses: 0.23900324367224032
Metrics: {'Acc@1': 0.9004777}
Best Acc@1 till now: 0.8975915312767029

Eval Metrics increased from: 0.8975915312767029 -> 0.9004777073860168
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.47 s

Epoch: 20
Mode: MODE.TRAIN
Losses: 0.22828128967253145
Metrics: {'Acc@1': 0.90630996}
Best Acc@1 till now: 0.9060901403427124

Train Metrics increased from: 0.9060901403427124 -> 0.906309962272644

Epoch: 20
Mode: MODE.EVAL
Losses: 0.2619390992127406
Metrics: {'Acc@1': 0.8897293}
Best Acc@1 till now: 0.9004777073860168

Epoch took 1015.13 s

Epoch: 21
Mode: MODE.TRAIN
Losses: 0.2236761264979382
Metrics: {'Acc@1': 0.9086277}
Best Acc@1 till now: 0.906309962272644

Train Metrics increased from: 0.906309962272644 -> 0.9086276888847351

Epoch: 21
Mode: MODE.EVAL
Losses: 0.2655617626039845
Metrics: {'Acc@1': 0.88724124}
Best Acc@1 till now: 0.9004777073860168

Epoch took 1014.96 s

Epoch: 22
Mode: MODE.TRAIN
Losses: 0.22270305434723034
Metrics: {'Acc@1': 0.90932703}
Best Acc@1 till now: 0.9086276888847351

Train Metrics increased from: 0.9086276888847351 -> 0.9093270301818848

Epoch: 22
Mode: MODE.EVAL
Losses: 0.25274595020303303
Metrics: {'Acc@1': 0.89490443}
Best Acc@1 till now: 0.9004777073860168

Epoch took 1015.36 s

Epoch: 23
Mode: MODE.TRAIN
Losses: 0.22015353207907562
Metrics: {'Acc@1': 0.90922713}
Best Acc@1 till now: 0.9093270301818848


Epoch: 23
Mode: MODE.EVAL
Losses: 0.23879773373816424
Metrics: {'Acc@1': 0.90326434}
Best Acc@1 till now: 0.9004777073860168

Eval Metrics increased from: 0.9004777073860168 -> 0.9032643437385559
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.62 s

Epoch: 24
Mode: MODE.TRAIN
Losses: 0.21738680396848323
Metrics: {'Acc@1': 0.9106857}
Best Acc@1 till now: 0.9093270301818848

Train Metrics increased from: 0.9093270301818848 -> 0.9106857180595398

Epoch: 24
Mode: MODE.EVAL
Losses: 0.25950752312590364
Metrics: {'Acc@1': 0.89341164}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1015.24 s

Epoch: 25
Mode: MODE.TRAIN
Losses: 0.2146430267187793
Metrics: {'Acc@1': 0.91214436}
Best Acc@1 till now: 0.9106857180595398

Train Metrics increased from: 0.9106857180595398 -> 0.9121443629264832

Epoch: 25
Mode: MODE.EVAL
Losses: 0.24951313621109458
Metrics: {'Acc@1': 0.8994825}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.88 s

Epoch: 26
Mode: MODE.TRAIN
Losses: 0.21143833661208983
Metrics: {'Acc@1': 0.91350305}
Best Acc@1 till now: 0.9121443629264832

Train Metrics increased from: 0.9121443629264832 -> 0.9135030508041382

Epoch: 26
Mode: MODE.EVAL
Losses: 0.2563448334290723
Metrics: {'Acc@1': 0.8935112}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.70 s

Epoch: 27
Mode: MODE.TRAIN
Losses: 0.20930074170574814
Metrics: {'Acc@1': 0.9161205}
Best Acc@1 till now: 0.9135030508041382

Train Metrics increased from: 0.9135030508041382 -> 0.9161205291748047

Epoch: 27
Mode: MODE.EVAL
Losses: 0.2781685767280068
Metrics: {'Acc@1': 0.881668}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.68 s

Epoch: 28
Mode: MODE.TRAIN
Losses: 0.20713404986216588
Metrics: {'Acc@1': 0.91568094}
Best Acc@1 till now: 0.9161205291748047


Epoch: 28
Mode: MODE.EVAL
Losses: 0.2711921935058703
Metrics: {'Acc@1': 0.8873408}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.79 s

Epoch: 29
Mode: MODE.TRAIN
Losses: 0.20594338792592973
Metrics: {'Acc@1': 0.9169797}
Best Acc@1 till now: 0.9161205291748047

Train Metrics increased from: 0.9161205291748047 -> 0.9169796705245972

Epoch: 29
Mode: MODE.EVAL
Losses: 0.34484696150964994
Metrics: {'Acc@1': 0.85638934}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.67 s

Epoch: 30
Mode: MODE.TRAIN
Losses: 0.20287787220667086
Metrics: {'Acc@1': 0.91650015}
Best Acc@1 till now: 0.9169796705245972


Epoch: 30
Mode: MODE.EVAL
Losses: 0.2645562503747879
Metrics: {'Acc@1': 0.8943073}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.90 s

Epoch: 31
Mode: MODE.TRAIN
Losses: 0.1995603409131317
Metrics: {'Acc@1': 0.9196571}
Best Acc@1 till now: 0.9169796705245972

Train Metrics increased from: 0.9169796705245972 -> 0.9196571111679077

Epoch: 31
Mode: MODE.EVAL
Losses: 0.24339705292776131
Metrics: {'Acc@1': 0.90057725}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.87 s

Epoch: 32
Mode: MODE.TRAIN
Losses: 0.19810719602286359
Metrics: {'Acc@1': 0.9205163}
Best Acc@1 till now: 0.9196571111679077

Train Metrics increased from: 0.9196571111679077 -> 0.920516312122345

Epoch: 32
Mode: MODE.EVAL
Losses: 0.3413672022948599
Metrics: {'Acc@1': 0.86664015}
Best Acc@1 till now: 0.9032643437385559

Epoch took 1014.93 s

Epoch: 33
Mode: MODE.TRAIN
Losses: 0.1948761122391733
Metrics: {'Acc@1': 0.9211357}
Best Acc@1 till now: 0.920516312122345

Train Metrics increased from: 0.920516312122345 -> 0.9211357235908508

Epoch: 33
Mode: MODE.EVAL
Losses: 0.23565543656516227
Metrics: {'Acc@1': 0.90425956}
Best Acc@1 till now: 0.9032643437385559

Eval Metrics increased from: 0.9032643437385559 -> 0.9042595624923706
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.79 s

Epoch: 34
Mode: MODE.TRAIN
Losses: 0.1950337745754234
Metrics: {'Acc@1': 0.92097586}
Best Acc@1 till now: 0.9211357235908508


Epoch: 34
Mode: MODE.EVAL
Losses: 0.22749389107724663
Metrics: {'Acc@1': 0.90744424}
Best Acc@1 till now: 0.9042595624923706

Eval Metrics increased from: 0.9042595624923706 -> 0.9074442386627197
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.96 s

Epoch: 35
Mode: MODE.TRAIN
Losses: 0.19055048857941803
Metrics: {'Acc@1': 0.92305386}
Best Acc@1 till now: 0.9211357235908508

Train Metrics increased from: 0.9211357235908508 -> 0.9230538606643677

Epoch: 35
Mode: MODE.EVAL
Losses: 0.2635700133196108
Metrics: {'Acc@1': 0.8923169}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.55 s

Epoch: 36
Mode: MODE.TRAIN
Losses: 0.18869048735255475
Metrics: {'Acc@1': 0.9242927}
Best Acc@1 till now: 0.9230538606643677

Train Metrics increased from: 0.9230538606643677 -> 0.9242926836013794

Epoch: 36
Mode: MODE.EVAL
Losses: 0.24463538365189436
Metrics: {'Acc@1': 0.89928347}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.18 s

Epoch: 37
Mode: MODE.TRAIN
Losses: 0.1864830335063855
Metrics: {'Acc@1': 0.92445254}
Best Acc@1 till now: 0.9242926836013794

Train Metrics increased from: 0.9242926836013794 -> 0.924452543258667

Epoch: 37
Mode: MODE.EVAL
Losses: 0.2338618234179582
Metrics: {'Acc@1': 0.90515524}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.24 s

Epoch: 38
Mode: MODE.TRAIN
Losses: 0.18514910161666706
Metrics: {'Acc@1': 0.9251918}
Best Acc@1 till now: 0.924452543258667

Train Metrics increased from: 0.924452543258667 -> 0.9251918196678162

Epoch: 38
Mode: MODE.EVAL
Losses: 0.38213706548046916
Metrics: {'Acc@1': 0.8528065}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.48 s

Epoch: 39
Mode: MODE.TRAIN
Losses: 0.18343849008536095
Metrics: {'Acc@1': 0.9254316}
Best Acc@1 till now: 0.9251918196678162

Train Metrics increased from: 0.9251918196678162 -> 0.9254316091537476

Epoch: 39
Mode: MODE.EVAL
Losses: 0.2507792665700244
Metrics: {'Acc@1': 0.9037619}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.29 s

Epoch: 40
Mode: MODE.TRAIN
Losses: 0.18100231707743977
Metrics: {'Acc@1': 0.9264506}
Best Acc@1 till now: 0.9254316091537476

Train Metrics increased from: 0.9254316091537476 -> 0.9264506101608276

Epoch: 40
Mode: MODE.EVAL
Losses: 0.235405042577701
Metrics: {'Acc@1': 0.9043591}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.56 s

Epoch: 41
Mode: MODE.TRAIN
Losses: 0.17871298638584515
Metrics: {'Acc@1': 0.92764944}
Best Acc@1 till now: 0.9264506101608276

Train Metrics increased from: 0.9264506101608276 -> 0.9276494383811951

Epoch: 41
Mode: MODE.EVAL
Losses: 0.23568865196530225
Metrics: {'Acc@1': 0.90694666}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.35 s

Epoch: 42
Mode: MODE.TRAIN
Losses: 0.17588605666461657
Metrics: {'Acc@1': 0.9296875}
Best Acc@1 till now: 0.9276494383811951

Train Metrics increased from: 0.9276494383811951 -> 0.9296875

Epoch: 42
Mode: MODE.EVAL
Losses: 0.23486853224836338
Metrics: {'Acc@1': 0.9068471}
Best Acc@1 till now: 0.9074442386627197

Epoch took 1014.89 s

Epoch: 43
Mode: MODE.TRAIN
Losses: 0.1737669250115638
Metrics: {'Acc@1': 0.9305267}
Best Acc@1 till now: 0.9296875

Train Metrics increased from: 0.9296875 -> 0.9305266737937927

Epoch: 43
Mode: MODE.EVAL
Losses: 0.23195870064056603
Metrics: {'Acc@1': 0.9091362}
Best Acc@1 till now: 0.9074442386627197

Eval Metrics increased from: 0.9074442386627197 -> 0.909136176109314
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.87 s

Epoch: 44
Mode: MODE.TRAIN
Losses: 0.1730620211176098
Metrics: {'Acc@1': 0.93048674}
Best Acc@1 till now: 0.9305266737937927


Epoch: 44
Mode: MODE.EVAL
Losses: 0.2329975013994867
Metrics: {'Acc@1': 0.9076433}
Best Acc@1 till now: 0.909136176109314

Epoch took 1014.48 s

Epoch: 45
Mode: MODE.TRAIN
Losses: 0.16933252934909537
Metrics: {'Acc@1': 0.9321451}
Best Acc@1 till now: 0.9305266737937927

Train Metrics increased from: 0.9305266737937927 -> 0.9321451187133789

Epoch: 45
Mode: MODE.EVAL
Losses: 0.24376850053193463
Metrics: {'Acc@1': 0.9052548}
Best Acc@1 till now: 0.909136176109314

Epoch took 1014.93 s

Epoch: 46
Mode: MODE.TRAIN
Losses: 0.14294847022846838
Metrics: {'Acc@1': 0.9435742}
Best Acc@1 till now: 0.9321451187133789

Train Metrics increased from: 0.9321451187133789 -> 0.9435741901397705

Epoch: 46
Mode: MODE.EVAL
Losses: 0.21691746098600376
Metrics: {'Acc@1': 0.9170979}
Best Acc@1 till now: 0.909136176109314

Eval Metrics increased from: 0.909136176109314 -> 0.9170979261398315
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.32 s

Epoch: 47
Mode: MODE.TRAIN
Losses: 0.13590178488637022
Metrics: {'Acc@1': 0.9483096}
Best Acc@1 till now: 0.9435741901397705

Train Metrics increased from: 0.9435741901397705 -> 0.948309600353241

Epoch: 47
Mode: MODE.EVAL
Losses: 0.21593967260448796
Metrics: {'Acc@1': 0.91729695}
Best Acc@1 till now: 0.9170979261398315

Eval Metrics increased from: 0.9170979261398315 -> 0.9172969460487366
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.13 s

Epoch: 48
Mode: MODE.TRAIN
Losses: 0.13258847117881337
Metrics: {'Acc@1': 0.9495484}
Best Acc@1 till now: 0.948309600353241

Train Metrics increased from: 0.948309600353241 -> 0.9495484232902527

Epoch: 48
Mode: MODE.EVAL
Losses: 0.22042786586246674
Metrics: {'Acc@1': 0.9161027}
Best Acc@1 till now: 0.9172969460487366

Epoch took 1014.40 s

Epoch: 49
Mode: MODE.TRAIN
Losses: 0.13062593567868708
Metrics: {'Acc@1': 0.95064735}
Best Acc@1 till now: 0.9495484232902527

Train Metrics increased from: 0.9495484232902527 -> 0.9506473541259766

Epoch: 49
Mode: MODE.EVAL
Losses: 0.2179225615587584
Metrics: {'Acc@1': 0.9173965}
Best Acc@1 till now: 0.9172969460487366

Eval Metrics increased from: 0.9172969460487366 -> 0.9173964858055115
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.02 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 1.5563764163600209
Metrics: {'Acc@1': 0.42131555}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.4213155508041382

Epoch: 0
Mode: MODE.EVAL
Losses: 1.5269436972915746
Metrics: {'Acc@1': 0.4312301}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.4312300980091095
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.54 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 1.3545744198819865
Metrics: {'Acc@1': 0.50121886}
Best Acc@1 till now: 0.4213155508041382

Train Metrics increased from: 0.4213155508041382 -> 0.501218855381012

Epoch: 1
Mode: MODE.EVAL
Losses: 1.4870861381482168
Metrics: {'Acc@1': 0.4499403}
Best Acc@1 till now: 0.4312300980091095

Eval Metrics increased from: 0.4312300980091095 -> 0.4499402940273285
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.74 s

Epoch: 2
Mode: MODE.TRAIN
Losses: 1.2815797276356642
Metrics: {'Acc@1': 0.5258352}
Best Acc@1 till now: 0.501218855381012

Train Metrics increased from: 0.501218855381012 -> 0.5258352160453796

Epoch: 2
Mode: MODE.EVAL
Losses: 1.3901177470091801
Metrics: {'Acc@1': 0.48905253}
Best Acc@1 till now: 0.4499402940273285

Eval Metrics increased from: 0.4499402940273285 -> 0.48905253410339355
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1015.89 s

Epoch: 3
Mode: MODE.TRAIN
Losses: 1.234061543289048
Metrics: {'Acc@1': 0.54703486}
Best Acc@1 till now: 0.5258352160453796

Train Metrics increased from: 0.5258352160453796 -> 0.5470348596572876

Epoch: 3
Mode: MODE.EVAL
Losses: 1.3752965410803533
Metrics: {'Acc@1': 0.5053742}
Best Acc@1 till now: 0.48905253410339355

Eval Metrics increased from: 0.48905253410339355 -> 0.5053741931915283
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.63 s

Epoch: 4
Mode: MODE.TRAIN
Losses: 1.198700956752538
Metrics: {'Acc@1': 0.56246006}
Best Acc@1 till now: 0.5470348596572876

Train Metrics increased from: 0.5470348596572876 -> 0.5624600648880005

Epoch: 4
Mode: MODE.EVAL
Losses: 1.4133662926922939
Metrics: {'Acc@1': 0.46934712}
Best Acc@1 till now: 0.5053741931915283

Epoch took 1014.25 s

Epoch: 5
Mode: MODE.TRAIN
Losses: 1.1734071055336681
Metrics: {'Acc@1': 0.57203084}
Best Acc@1 till now: 0.5624600648880005

Train Metrics increased from: 0.5624600648880005 -> 0.5720308423042297

Epoch: 5
Mode: MODE.EVAL
Losses: 1.2788701080212928
Metrics: {'Acc@1': 0.52806526}
Best Acc@1 till now: 0.5053741931915283

Eval Metrics increased from: 0.5053741931915283 -> 0.5280652642250061
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.13 s

Epoch: 6
Mode: MODE.TRAIN
Losses: 1.143520773066889
Metrics: {'Acc@1': 0.5847986}
Best Acc@1 till now: 0.5720308423042297

Train Metrics increased from: 0.5720308423042297 -> 0.5847985744476318

Epoch: 6
Mode: MODE.EVAL
Losses: 1.2847670658378845
Metrics: {'Acc@1': 0.53632563}
Best Acc@1 till now: 0.5280652642250061

Eval Metrics increased from: 0.5280652642250061 -> 0.5363256335258484
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.93 s

Epoch: 7
Mode: MODE.TRAIN
Losses: 1.1186279451755612
Metrics: {'Acc@1': 0.59299076}
Best Acc@1 till now: 0.5847985744476318

Train Metrics increased from: 0.5847985744476318 -> 0.5929907560348511

Epoch: 7
Mode: MODE.EVAL
Losses: 1.2596652917801194
Metrics: {'Acc@1': 0.5441879}
Best Acc@1 till now: 0.5363256335258484

Eval Metrics increased from: 0.5363256335258484 -> 0.5441879034042358
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.68 s

Epoch: 8
Mode: MODE.TRAIN
Losses: 1.0984182367696786
Metrics: {'Acc@1': 0.59974426}
Best Acc@1 till now: 0.5929907560348511

Train Metrics increased from: 0.5929907560348511 -> 0.5997442603111267

Epoch: 8
Mode: MODE.EVAL
Losses: 1.2482690275854367
Metrics: {'Acc@1': 0.5493631}
Best Acc@1 till now: 0.5441879034042358

Eval Metrics increased from: 0.5441879034042358 -> 0.5493630766868591
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.57 s

Epoch: 9
Mode: MODE.TRAIN
Losses: 1.079058976963048
Metrics: {'Acc@1': 0.6089554}
Best Acc@1 till now: 0.5997442603111267

Train Metrics increased from: 0.5997442603111267 -> 0.6089553833007812

Epoch: 9
Mode: MODE.EVAL
Losses: 1.2928847997051895
Metrics: {'Acc@1': 0.54160035}
Best Acc@1 till now: 0.5493630766868591

Epoch took 1014.32 s

Epoch: 10
Mode: MODE.TRAIN
Losses: 1.0611258611807128
Metrics: {'Acc@1': 0.61431026}
Best Acc@1 till now: 0.6089553833007812

Train Metrics increased from: 0.6089553833007812 -> 0.6143102645874023

Epoch: 10
Mode: MODE.EVAL
Losses: 1.2223543205838294
Metrics: {'Acc@1': 0.5594148}
Best Acc@1 till now: 0.5493630766868591

Eval Metrics increased from: 0.5493630766868591 -> 0.559414803981781
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.47 s

Epoch: 11
Mode: MODE.TRAIN
Losses: 1.0450680289427032
Metrics: {'Acc@1': 0.62054425}
Best Acc@1 till now: 0.6143102645874023

Train Metrics increased from: 0.6143102645874023 -> 0.6205442547798157

Epoch: 11
Mode: MODE.EVAL
Losses: 1.3222366954870284
Metrics: {'Acc@1': 0.5262739}
Best Acc@1 till now: 0.559414803981781

Epoch took 1014.16 s

Epoch: 12
Mode: MODE.TRAIN
Losses: 1.0272181835930672
Metrics: {'Acc@1': 0.6277574}
Best Acc@1 till now: 0.6205442547798157

Train Metrics increased from: 0.6205442547798157 -> 0.6277573704719543

Epoch: 12
Mode: MODE.EVAL
Losses: 1.238289581362609
Metrics: {'Acc@1': 0.55662817}
Best Acc@1 till now: 0.559414803981781

Epoch took 1014.38 s

Epoch: 13
Mode: MODE.TRAIN
Losses: 1.012455090384959
Metrics: {'Acc@1': 0.63289243}
Best Acc@1 till now: 0.6277573704719543

Train Metrics increased from: 0.6277573704719543 -> 0.6328924298286438

Epoch: 13
Mode: MODE.EVAL
Losses: 1.2171975089486238
Metrics: {'Acc@1': 0.5692675}
Best Acc@1 till now: 0.559414803981781

Eval Metrics increased from: 0.559414803981781 -> 0.5692675113677979
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.58 s

Epoch: 14
Mode: MODE.TRAIN
Losses: 0.996874631594514
Metrics: {'Acc@1': 0.64006555}
Best Acc@1 till now: 0.6328924298286438

Train Metrics increased from: 0.6328924298286438 -> 0.6400655508041382

Epoch: 14
Mode: MODE.EVAL
Losses: 1.2424938071305585
Metrics: {'Acc@1': 0.56041}
Best Acc@1 till now: 0.5692675113677979

Epoch took 1014.03 s

Epoch: 15
Mode: MODE.TRAIN
Losses: 0.9811506963446927
Metrics: {'Acc@1': 0.64548033}
Best Acc@1 till now: 0.6400655508041382

Train Metrics increased from: 0.6400655508041382 -> 0.6454803347587585

Epoch: 15
Mode: MODE.EVAL
Losses: 1.2043249459023688
Metrics: {'Acc@1': 0.5733479}
Best Acc@1 till now: 0.5692675113677979

Eval Metrics increased from: 0.5692675113677979 -> 0.5733479261398315
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.56 s

Epoch: 16
Mode: MODE.TRAIN
Losses: 0.9610922157459552
Metrics: {'Acc@1': 0.6521539}
Best Acc@1 till now: 0.6454803347587585

Train Metrics increased from: 0.6454803347587585 -> 0.6521539092063904

Epoch: 16
Mode: MODE.EVAL
Losses: 1.291350076912315
Metrics: {'Acc@1': 0.54259557}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.83 s

Epoch: 17
Mode: MODE.TRAIN
Losses: 0.9473466876979983
Metrics: {'Acc@1': 0.6586277}
Best Acc@1 till now: 0.6521539092063904

Train Metrics increased from: 0.6521539092063904 -> 0.6586276888847351

Epoch: 17
Mode: MODE.EVAL
Losses: 1.27523645663717
Metrics: {'Acc@1': 0.55374205}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.50 s

Epoch: 18
Mode: MODE.TRAIN
Losses: 0.9369806920933297
Metrics: {'Acc@1': 0.661505}
Best Acc@1 till now: 0.6586276888847351

Train Metrics increased from: 0.6586276888847351 -> 0.6615049839019775

Epoch: 18
Mode: MODE.EVAL
Losses: 1.2195632313467135
Metrics: {'Acc@1': 0.5709594}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.06 s

Epoch: 19
Mode: MODE.TRAIN
Losses: 0.9215018450451629
Metrics: {'Acc@1': 0.66731936}
Best Acc@1 till now: 0.6615049839019775

Train Metrics increased from: 0.6615049839019775 -> 0.6673193573951721

Epoch: 19
Mode: MODE.EVAL
Losses: 1.2422490032615177
Metrics: {'Acc@1': 0.5700637}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.12 s

Epoch: 20
Mode: MODE.TRAIN
Losses: 0.9061693314396208
Metrics: {'Acc@1': 0.6754316}
Best Acc@1 till now: 0.6673193573951721

Train Metrics increased from: 0.6673193573951721 -> 0.6754316091537476

Epoch: 20
Mode: MODE.EVAL
Losses: 1.3163706398313972
Metrics: {'Acc@1': 0.54697454}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.91 s

Epoch: 21
Mode: MODE.TRAIN
Losses: 0.8944135291497116
Metrics: {'Acc@1': 0.67816895}
Best Acc@1 till now: 0.6754316091537476

Train Metrics increased from: 0.6754316091537476 -> 0.6781689524650574

Epoch: 21
Mode: MODE.EVAL
Losses: 1.2614918764989087
Metrics: {'Acc@1': 0.56011146}
Best Acc@1 till now: 0.5733479261398315

Epoch took 1014.58 s

Epoch: 22
Mode: MODE.TRAIN
Losses: 0.8768295471168235
Metrics: {'Acc@1': 0.68202525}
Best Acc@1 till now: 0.6781689524650574

Train Metrics increased from: 0.6781689524650574 -> 0.6820252537727356

Epoch: 22
Mode: MODE.EVAL
Losses: 1.1919878277049702
Metrics: {'Acc@1': 0.5869825}
Best Acc@1 till now: 0.5733479261398315

Eval Metrics increased from: 0.5733479261398315 -> 0.5869824886322021
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.27 s

Epoch: 23
Mode: MODE.TRAIN
Losses: 0.8637704218897369
Metrics: {'Acc@1': 0.68608135}
Best Acc@1 till now: 0.6820252537727356

Train Metrics increased from: 0.6820252537727356 -> 0.6860813498497009

Epoch: 23
Mode: MODE.EVAL
Losses: 1.3262037475397632
Metrics: {'Acc@1': 0.54946256}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.13 s

Epoch: 24
Mode: MODE.TRAIN
Losses: 0.851121872968381
Metrics: {'Acc@1': 0.6938739}
Best Acc@1 till now: 0.6860813498497009

Train Metrics increased from: 0.6860813498497009 -> 0.6938738822937012

Epoch: 24
Mode: MODE.EVAL
Losses: 1.210728859066204
Metrics: {'Acc@1': 0.5818073}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.33 s

Epoch: 25
Mode: MODE.TRAIN
Losses: 0.8355855185662389
Metrics: {'Acc@1': 0.6967511}
Best Acc@1 till now: 0.6938738822937012

Train Metrics increased from: 0.6938738822937012 -> 0.6967511177062988

Epoch: 25
Mode: MODE.EVAL
Losses: 1.2527681562551267
Metrics: {'Acc@1': 0.5688694}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.10 s

Epoch: 26
Mode: MODE.TRAIN
Losses: 0.8160993907686389
Metrics: {'Acc@1': 0.7063019}
Best Acc@1 till now: 0.6967511177062988

Train Metrics increased from: 0.6967511177062988 -> 0.7063019275665283

Epoch: 26
Mode: MODE.EVAL
Losses: 1.2364426832290212
Metrics: {'Acc@1': 0.5725517}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.21 s

Epoch: 27
Mode: MODE.TRAIN
Losses: 0.8029610300460435
Metrics: {'Acc@1': 0.7111373}
Best Acc@1 till now: 0.7063019275665283

Train Metrics increased from: 0.7063019275665283 -> 0.7111372947692871

Epoch: 27
Mode: MODE.EVAL
Losses: 1.2296571291176377
Metrics: {'Acc@1': 0.58638537}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1013.99 s

Epoch: 28
Mode: MODE.TRAIN
Losses: 0.7869065956920004
Metrics: {'Acc@1': 0.7162324}
Best Acc@1 till now: 0.7111372947692871

Train Metrics increased from: 0.7111372947692871 -> 0.716232419013977

Epoch: 28
Mode: MODE.EVAL
Losses: 1.2489821846318092
Metrics: {'Acc@1': 0.5846935}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.37 s

Epoch: 29
Mode: MODE.TRAIN
Losses: 0.7708415610101217
Metrics: {'Acc@1': 0.7212676}
Best Acc@1 till now: 0.716232419013977

Train Metrics increased from: 0.716232419013977 -> 0.721267580986023

Epoch: 29
Mode: MODE.EVAL
Losses: 1.2374919812390759
Metrics: {'Acc@1': 0.57703024}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.42 s

Epoch: 30
Mode: MODE.TRAIN
Losses: 0.7561718637071302
Metrics: {'Acc@1': 0.7267623}
Best Acc@1 till now: 0.721267580986023

Train Metrics increased from: 0.721267580986023 -> 0.7267622947692871

Epoch: 30
Mode: MODE.EVAL
Losses: 1.2591922169278382
Metrics: {'Acc@1': 0.5799164}
Best Acc@1 till now: 0.5869824886322021

Epoch took 1014.35 s

Epoch: 31
Mode: MODE.TRAIN
Losses: 0.7427439786817717
Metrics: {'Acc@1': 0.73097825}
Best Acc@1 till now: 0.7267622947692871

Train Metrics increased from: 0.7267622947692871 -> 0.73097825050354

Epoch: 31
Mode: MODE.EVAL
Losses: 1.2049166765182642
Metrics: {'Acc@1': 0.5950438}
Best Acc@1 till now: 0.5869824886322021

Eval Metrics increased from: 0.5869824886322021 -> 0.5950437784194946
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.56 s

Epoch: 32
Mode: MODE.TRAIN
Losses: 0.7271516196182012
Metrics: {'Acc@1': 0.74090874}
Best Acc@1 till now: 0.73097825050354

Train Metrics increased from: 0.73097825050354 -> 0.7409087419509888

Epoch: 32
Mode: MODE.EVAL
Losses: 1.2312874319447074
Metrics: {'Acc@1': 0.5883758}
Best Acc@1 till now: 0.5950437784194946

Epoch took 1014.59 s

Epoch: 33
Mode: MODE.TRAIN
Losses: 0.7097035284008821
Metrics: {'Acc@1': 0.74428546}
Best Acc@1 till now: 0.7409087419509888

Train Metrics increased from: 0.7409087419509888 -> 0.7442854642868042

Epoch: 33
Mode: MODE.EVAL
Losses: 1.3433658571759606
Metrics: {'Acc@1': 0.5575239}
Best Acc@1 till now: 0.5950437784194946

Epoch took 1014.26 s

Epoch: 34
Mode: MODE.TRAIN
Losses: 0.5602426977871019
Metrics: {'Acc@1': 0.80712515}
Best Acc@1 till now: 0.7442854642868042

Train Metrics increased from: 0.7442854642868042 -> 0.8071251511573792

Epoch: 34
Mode: MODE.EVAL
Losses: 1.1080678033221298
Metrics: {'Acc@1': 0.63087183}
Best Acc@1 till now: 0.5950437784194946

Eval Metrics increased from: 0.5950437784194946 -> 0.6308718323707581
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.96 s

Epoch: 35
Mode: MODE.TRAIN
Losses: 0.5245121330632578
Metrics: {'Acc@1': 0.82338953}
Best Acc@1 till now: 0.8071251511573792

Train Metrics increased from: 0.8071251511573792 -> 0.8233895301818848

Epoch: 35
Mode: MODE.EVAL
Losses: 1.1094667752077625
Metrics: {'Acc@1': 0.6285828}
Best Acc@1 till now: 0.6308718323707581

Epoch took 1014.57 s

Epoch: 36
Mode: MODE.TRAIN
Losses: 0.5133750360944996
Metrics: {'Acc@1': 0.8284647}
Best Acc@1 till now: 0.8233895301818848

Train Metrics increased from: 0.8233895301818848 -> 0.828464686870575

Epoch: 36
Mode: MODE.EVAL
Losses: 1.1060662793505722
Metrics: {'Acc@1': 0.63236463}
Best Acc@1 till now: 0.6308718323707581

Eval Metrics increased from: 0.6308718323707581 -> 0.6323646306991577
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1017.06 s

Epoch: 37
Mode: MODE.TRAIN
Losses: 0.5033520458223265
Metrics: {'Acc@1': 0.83200127}
Best Acc@1 till now: 0.828464686870575

Train Metrics increased from: 0.828464686870575 -> 0.832001268863678

Epoch: 37
Mode: MODE.EVAL
Losses: 1.113513731652764
Metrics: {'Acc@1': 0.6297771}
Best Acc@1 till now: 0.6323646306991577

Epoch took 1014.77 s

Epoch: 38
Mode: MODE.TRAIN
Losses: 0.49501064697952224
Metrics: {'Acc@1': 0.83451885}
Best Acc@1 till now: 0.832001268863678

Train Metrics increased from: 0.832001268863678 -> 0.8345188498497009

Epoch: 38
Mode: MODE.EVAL
Losses: 1.122213063726
Metrics: {'Acc@1': 0.6288814}
Best Acc@1 till now: 0.6323646306991577

Epoch took 1014.51 s

Epoch: 39
Mode: MODE.TRAIN
Losses: 0.4870603205374135
Metrics: {'Acc@1': 0.8370964}
Best Acc@1 till now: 0.8345188498497009

Train Metrics increased from: 0.8345188498497009 -> 0.8370963931083679

Epoch: 39
Mode: MODE.EVAL
Losses: 1.1196249279246968
Metrics: {'Acc@1': 0.63226515}
Best Acc@1 till now: 0.6323646306991577

Epoch took 1014.52 s

Epoch: 40
Mode: MODE.TRAIN
Losses: 0.48386430561237626
Metrics: {'Acc@1': 0.83817536}
Best Acc@1 till now: 0.8370963931083679

Train Metrics increased from: 0.8370963931083679 -> 0.838175356388092

Epoch: 40
Mode: MODE.EVAL
Losses: 1.1279812952515427
Metrics: {'Acc@1': 0.63415605}
Best Acc@1 till now: 0.6323646306991577

Eval Metrics increased from: 0.6323646306991577 -> 0.6341560482978821
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693304927.pt
Epoch took 1016.91 s

Epoch: 41
Mode: MODE.TRAIN
Losses: 0.4774840320353313
Metrics: {'Acc@1': 0.8404132}
Best Acc@1 till now: 0.838175356388092

Train Metrics increased from: 0.838175356388092 -> 0.8404132127761841

Epoch: 41
Mode: MODE.EVAL
Losses: 1.1259956409217446
Metrics: {'Acc@1': 0.63375795}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.24 s

Epoch: 42
Mode: MODE.TRAIN
Losses: 0.468899926566102
Metrics: {'Acc@1': 0.8435102}
Best Acc@1 till now: 0.8404132127761841

Train Metrics increased from: 0.8404132127761841 -> 0.8435102105140686

Epoch: 42
Mode: MODE.EVAL
Losses: 1.1358840987560854
Metrics: {'Acc@1': 0.63236463}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.49 s

Epoch: 43
Mode: MODE.TRAIN
Losses: 0.4625663240166271
Metrics: {'Acc@1': 0.84682703}
Best Acc@1 till now: 0.8435102105140686

Train Metrics increased from: 0.8435102105140686 -> 0.8468270301818848

Epoch: 43
Mode: MODE.EVAL
Losses: 1.1452769113194412
Metrics: {'Acc@1': 0.62917995}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.31 s

Epoch: 44
Mode: MODE.TRAIN
Losses: 0.46322590040276423
Metrics: {'Acc@1': 0.8461677}
Best Acc@1 till now: 0.8468270301818848


Epoch: 44
Mode: MODE.EVAL
Losses: 1.143997293369026
Metrics: {'Acc@1': 0.6331608}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.50 s

Epoch: 45
Mode: MODE.TRAIN
Losses: 0.4541978298322014
Metrics: {'Acc@1': 0.84966433}
Best Acc@1 till now: 0.8468270301818848

Train Metrics increased from: 0.8468270301818848 -> 0.8496643304824829

Epoch: 45
Mode: MODE.EVAL
Losses: 1.1454172069859352
Metrics: {'Acc@1': 0.6299761}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.16 s

Epoch: 46
Mode: MODE.TRAIN
Losses: 0.4515606439517587
Metrics: {'Acc@1': 0.84836555}
Best Acc@1 till now: 0.8496643304824829


Epoch: 46
Mode: MODE.EVAL
Losses: 1.1460734123636962
Metrics: {'Acc@1': 0.63236463}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.58 s

Epoch: 47
Mode: MODE.TRAIN
Losses: 0.44507464316799816
Metrics: {'Acc@1': 0.8511429}
Best Acc@1 till now: 0.8496643304824829

Train Metrics increased from: 0.8496643304824829 -> 0.8511428833007812

Epoch: 47
Mode: MODE.EVAL
Losses: 1.1516262972430817
Metrics: {'Acc@1': 0.63107085}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.80 s

Epoch: 48
Mode: MODE.TRAIN
Losses: 0.42494989095060415
Metrics: {'Acc@1': 0.8600943}
Best Acc@1 till now: 0.8511428833007812

Train Metrics increased from: 0.8511428833007812 -> 0.8600943088531494

Epoch: 48
Mode: MODE.EVAL
Losses: 1.1426600787290342
Metrics: {'Acc@1': 0.6320661}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.45 s

Epoch: 49
Mode: MODE.TRAIN
Losses: 0.4238369039752904
Metrics: {'Acc@1': 0.86283165}
Best Acc@1 till now: 0.8600943088531494

Train Metrics increased from: 0.8600943088531494 -> 0.8628316521644592

Epoch: 49
Mode: MODE.EVAL
Losses: 1.145460178897639
Metrics: {'Acc@1': 0.6334594}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.16 s

Epoch: 50
Mode: MODE.TRAIN
Losses: 0.4185050299291111
Metrics: {'Acc@1': 0.8650096}
Best Acc@1 till now: 0.8628316521644592

Train Metrics increased from: 0.8628316521644592 -> 0.865009605884552

Epoch: 50
Mode: MODE.EVAL
Losses: 1.1476901538053137
Metrics: {'Acc@1': 0.63226515}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.46 s

Epoch: 51
Mode: MODE.TRAIN
Losses: 0.4146698784950139
Metrics: {'Acc@1': 0.8650096}
Best Acc@1 till now: 0.865009605884552


Epoch: 51
Mode: MODE.EVAL
Losses: 1.1442574794125404
Metrics: {'Acc@1': 0.6325637}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.55 s

Epoch: 52
Mode: MODE.TRAIN
Losses: 0.41522717588316754
Metrics: {'Acc@1': 0.8670476}
Best Acc@1 till now: 0.865009605884552

Train Metrics increased from: 0.865009605884552 -> 0.8670476078987122

Epoch: 52
Mode: MODE.EVAL
Losses: 1.146987689908143
Metrics: {'Acc@1': 0.63375795}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.92 s

Epoch: 53
Mode: MODE.TRAIN
Losses: 0.4145766875666121
Metrics: {'Acc@1': 0.8659887}
Best Acc@1 till now: 0.8670476078987122


Epoch: 53
Mode: MODE.EVAL
Losses: 1.145134050375337
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.21 s

Epoch: 54
Mode: MODE.TRAIN
Losses: 0.4155054014471486
Metrics: {'Acc@1': 0.8659287}
Best Acc@1 till now: 0.8670476078987122


Epoch: 54
Mode: MODE.EVAL
Losses: 1.1505662476181224
Metrics: {'Acc@1': 0.6329618}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.69 s

Epoch: 55
Mode: MODE.TRAIN
Losses: 0.41671839101082836
Metrics: {'Acc@1': 0.86528933}
Best Acc@1 till now: 0.8670476078987122


Epoch: 55
Mode: MODE.EVAL
Losses: 1.1491391749898339
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.19 s

Epoch: 56
Mode: MODE.TRAIN
Losses: 0.4148042354627948
Metrics: {'Acc@1': 0.8674672}
Best Acc@1 till now: 0.8670476078987122

Train Metrics increased from: 0.8670476078987122 -> 0.8674672245979309

Epoch: 56
Mode: MODE.EVAL
Losses: 1.152289429667649
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.57 s

Epoch: 57
Mode: MODE.TRAIN
Losses: 0.4124768194563858
Metrics: {'Acc@1': 0.86706764}
Best Acc@1 till now: 0.8674672245979309


Epoch: 57
Mode: MODE.EVAL
Losses: 1.1514565796609137
Metrics: {'Acc@1': 0.6309713}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.78 s

Epoch: 58
Mode: MODE.TRAIN
Losses: 0.41267205264104906
Metrics: {'Acc@1': 0.86586875}
Best Acc@1 till now: 0.8674672245979309


Epoch: 58
Mode: MODE.EVAL
Losses: 1.152688893922575
Metrics: {'Acc@1': 0.63146895}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.34 s

Epoch: 59
Mode: MODE.TRAIN
Losses: 0.4112265204529628
Metrics: {'Acc@1': 0.86716753}
Best Acc@1 till now: 0.8674672245979309


Epoch: 59
Mode: MODE.EVAL
Losses: 1.1510488911039511
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.41 s

Epoch: 60
Mode: MODE.TRAIN
Losses: 0.4088692530189329
Metrics: {'Acc@1': 0.86734736}
Best Acc@1 till now: 0.8674672245979309


Epoch: 60
Mode: MODE.EVAL
Losses: 1.1511252784425285
Metrics: {'Acc@1': 0.6326632}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.54 s

Epoch: 61
Mode: MODE.TRAIN
Losses: 0.4079847797522764
Metrics: {'Acc@1': 0.86914563}
Best Acc@1 till now: 0.8674672245979309

Train Metrics increased from: 0.8674672245979309 -> 0.8691456317901611

Epoch: 61
Mode: MODE.EVAL
Losses: 1.1526890681807402
Metrics: {'Acc@1': 0.6320661}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.25 s

Epoch: 62
Mode: MODE.TRAIN
Losses: 0.40718383300106237
Metrics: {'Acc@1': 0.87004477}
Best Acc@1 till now: 0.8691456317901611

Train Metrics increased from: 0.8691456317901611 -> 0.8700447678565979

Epoch: 62
Mode: MODE.EVAL
Losses: 1.1488711697280787
Metrics: {'Acc@1': 0.63226515}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.55 s

Epoch: 63
Mode: MODE.TRAIN
Losses: 0.409214492096468
Metrics: {'Acc@1': 0.8689658}
Best Acc@1 till now: 0.8700447678565979


Epoch: 63
Mode: MODE.EVAL
Losses: 1.1500462988379654
Metrics: {'Acc@1': 0.6309713}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.67 s

Epoch: 64
Mode: MODE.TRAIN
Losses: 0.41192281362421984
Metrics: {'Acc@1': 0.86744726}
Best Acc@1 till now: 0.8700447678565979


Epoch: 64
Mode: MODE.EVAL
Losses: 1.1495608543134799
Metrics: {'Acc@1': 0.6313694}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.99 s

Epoch: 65
Mode: MODE.TRAIN
Losses: 0.4121252234139101
Metrics: {'Acc@1': 0.8682265}
Best Acc@1 till now: 0.8700447678565979


Epoch: 65
Mode: MODE.EVAL
Losses: 1.155236339113515
Metrics: {'Acc@1': 0.63107085}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.44 s

Epoch: 66
Mode: MODE.TRAIN
Losses: 0.4102994973968972
Metrics: {'Acc@1': 0.8666081}
Best Acc@1 till now: 0.8700447678565979


Epoch: 66
Mode: MODE.EVAL
Losses: 1.1491247252294212
Metrics: {'Acc@1': 0.63146895}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.29 s

Epoch: 67
Mode: MODE.TRAIN
Losses: 0.4089916463360152
Metrics: {'Acc@1': 0.8686261}
Best Acc@1 till now: 0.8700447678565979


Epoch: 67
Mode: MODE.EVAL
Losses: 1.149941817210738
Metrics: {'Acc@1': 0.631668}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.43 s

Epoch: 68
Mode: MODE.TRAIN
Losses: 0.40915187939887154
Metrics: {'Acc@1': 0.8689258}
Best Acc@1 till now: 0.8700447678565979


Epoch: 68
Mode: MODE.EVAL
Losses: 1.1507033637374828
Metrics: {'Acc@1': 0.6326632}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.59 s

Epoch: 69
Mode: MODE.TRAIN
Losses: 0.40860700811190376
Metrics: {'Acc@1': 0.8683464}
Best Acc@1 till now: 0.8700447678565979


Epoch: 69
Mode: MODE.EVAL
Losses: 1.1544365412110735
Metrics: {'Acc@1': 0.6320661}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.10 s

Epoch: 70
Mode: MODE.TRAIN
Losses: 0.4085643373982376
Metrics: {'Acc@1': 0.8703644}
Best Acc@1 till now: 0.8700447678565979

Train Metrics increased from: 0.8700447678565979 -> 0.8703644275665283

Epoch: 70
Mode: MODE.EVAL
Losses: 1.153251735268125
Metrics: {'Acc@1': 0.6313694}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.09 s

Epoch: 71
Mode: MODE.TRAIN
Losses: 0.40928981742819254
Metrics: {'Acc@1': 0.86840636}
Best Acc@1 till now: 0.8703644275665283


Epoch: 71
Mode: MODE.EVAL
Losses: 1.151446207693428
Metrics: {'Acc@1': 0.63146895}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.32 s

Epoch: 72
Mode: MODE.TRAIN
Losses: 0.4105220350348736
Metrics: {'Acc@1': 0.8689658}
Best Acc@1 till now: 0.8703644275665283


Epoch: 72
Mode: MODE.EVAL
Losses: 1.1525516616311042
Metrics: {'Acc@1': 0.6313694}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.20 s

Epoch: 73
Mode: MODE.TRAIN
Losses: 0.40827651904976886
Metrics: {'Acc@1': 0.8676271}
Best Acc@1 till now: 0.8703644275665283


Epoch: 73
Mode: MODE.EVAL
Losses: 1.150560033549169
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.22 s

Epoch: 74
Mode: MODE.TRAIN
Losses: 0.41019301509003503
Metrics: {'Acc@1': 0.8675272}
Best Acc@1 till now: 0.8703644275665283


Epoch: 74
Mode: MODE.EVAL
Losses: 1.1502379904127424
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.37 s

Epoch: 75
Mode: MODE.TRAIN
Losses: 0.4090446067397552
Metrics: {'Acc@1': 0.8704244}
Best Acc@1 till now: 0.8703644275665283

Train Metrics increased from: 0.8703644275665283 -> 0.8704243898391724

Epoch: 75
Mode: MODE.EVAL
Losses: 1.1509692570206467
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.45 s

Epoch: 76
Mode: MODE.TRAIN
Losses: 0.4109542937306187
Metrics: {'Acc@1': 0.8675871}
Best Acc@1 till now: 0.8704243898391724


Epoch: 76
Mode: MODE.EVAL
Losses: 1.1508376370569704
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.40 s

Epoch: 77
Mode: MODE.TRAIN
Losses: 0.4087030993741187
Metrics: {'Acc@1': 0.8681066}
Best Acc@1 till now: 0.8704243898391724


Epoch: 77
Mode: MODE.EVAL
Losses: 1.1508672055165479
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.86 s

Epoch: 78
Mode: MODE.TRAIN
Losses: 0.40830836157359734
Metrics: {'Acc@1': 0.86740726}
Best Acc@1 till now: 0.8704243898391724


Epoch: 78
Mode: MODE.EVAL
Losses: 1.1491432334207425
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.21 s

Epoch: 79
Mode: MODE.TRAIN
Losses: 0.4088687331170377
Metrics: {'Acc@1': 0.86894584}
Best Acc@1 till now: 0.8704243898391724


Epoch: 79
Mode: MODE.EVAL
Losses: 1.1545355764164287
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.22 s

Epoch: 80
Mode: MODE.TRAIN
Losses: 0.41088793504878385
Metrics: {'Acc@1': 0.86610854}
Best Acc@1 till now: 0.8704243898391724


Epoch: 80
Mode: MODE.EVAL
Losses: 1.152170581802441
Metrics: {'Acc@1': 0.63126993}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.40 s

Epoch: 81
Mode: MODE.TRAIN
Losses: 0.4101136626909151
Metrics: {'Acc@1': 0.8675871}
Best Acc@1 till now: 0.8704243898391724


Epoch: 81
Mode: MODE.EVAL
Losses: 1.151726179062181
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.98 s

Epoch: 82
Mode: MODE.TRAIN
Losses: 0.4098353489013889
Metrics: {'Acc@1': 0.8682265}
Best Acc@1 till now: 0.8704243898391724


Epoch: 82
Mode: MODE.EVAL
Losses: 1.1530195801121415
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.34 s

Epoch: 83
Mode: MODE.TRAIN
Losses: 0.408013888713344
Metrics: {'Acc@1': 0.86880594}
Best Acc@1 till now: 0.8704243898391724


Epoch: 83
Mode: MODE.EVAL
Losses: 1.1492355925262354
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.17 s

Epoch: 84
Mode: MODE.TRAIN
Losses: 0.40711938723197677
Metrics: {'Acc@1': 0.87004477}
Best Acc@1 till now: 0.8704243898391724


Epoch: 84
Mode: MODE.EVAL
Losses: 1.1513005794992872
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.30 s

Epoch: 85
Mode: MODE.TRAIN
Losses: 0.40892970110373117
Metrics: {'Acc@1': 0.8693654}
Best Acc@1 till now: 0.8704243898391724


Epoch: 85
Mode: MODE.EVAL
Losses: 1.1497508651891333
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.24 s

Epoch: 86
Mode: MODE.TRAIN
Losses: 0.40844807571843456
Metrics: {'Acc@1': 0.86932546}
Best Acc@1 till now: 0.8704243898391724


Epoch: 86
Mode: MODE.EVAL
Losses: 1.1501372688135523
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.64 s

Epoch: 87
Mode: MODE.TRAIN
Losses: 0.4090219531637019
Metrics: {'Acc@1': 0.8684862}
Best Acc@1 till now: 0.8704243898391724


Epoch: 87
Mode: MODE.EVAL
Losses: 1.1498088483597821
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.35 s

Epoch: 88
Mode: MODE.TRAIN
Losses: 0.41075758182484173
Metrics: {'Acc@1': 0.86744726}
Best Acc@1 till now: 0.8704243898391724


Epoch: 88
Mode: MODE.EVAL
Losses: 1.1509943353902004
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.13 s

Epoch: 89
Mode: MODE.TRAIN
Losses: 0.4082247502244342
Metrics: {'Acc@1': 0.86856616}
Best Acc@1 till now: 0.8704243898391724


Epoch: 89
Mode: MODE.EVAL
Losses: 1.1516790033146074
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.38 s

Epoch: 90
Mode: MODE.TRAIN
Losses: 0.4083884483789239
Metrics: {'Acc@1': 0.86828643}
Best Acc@1 till now: 0.8704243898391724


Epoch: 90
Mode: MODE.EVAL
Losses: 1.1500104202586374
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.17 s

Epoch: 91
Mode: MODE.TRAIN
Losses: 0.4080171716944946
Metrics: {'Acc@1': 0.86870605}
Best Acc@1 till now: 0.8704243898391724


Epoch: 91
Mode: MODE.EVAL
Losses: 1.1521387198928055
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.98 s

Epoch: 92
Mode: MODE.TRAIN
Losses: 0.40939864308556634
Metrics: {'Acc@1': 0.86818653}
Best Acc@1 till now: 0.8704243898391724


Epoch: 92
Mode: MODE.EVAL
Losses: 1.1516562586377381
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.93 s

Epoch: 93
Mode: MODE.TRAIN
Losses: 0.4087110256676174
Metrics: {'Acc@1': 0.86798674}
Best Acc@1 till now: 0.8704243898391724


Epoch: 93
Mode: MODE.EVAL
Losses: 1.1530178766341725
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.50 s

Epoch: 94
Mode: MODE.TRAIN
Losses: 0.40594439027483203
Metrics: {'Acc@1': 0.8701247}
Best Acc@1 till now: 0.8704243898391724


Epoch: 94
Mode: MODE.EVAL
Losses: 1.1503088869106997
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.18 s

Epoch: 95
Mode: MODE.TRAIN
Losses: 0.4070266348207393
Metrics: {'Acc@1': 0.869745}
Best Acc@1 till now: 0.8704243898391724


Epoch: 95
Mode: MODE.EVAL
Losses: 1.1502216276089856
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.04 s

Epoch: 96
Mode: MODE.TRAIN
Losses: 0.4097394330231735
Metrics: {'Acc@1': 0.8686461}
Best Acc@1 till now: 0.8704243898391724


Epoch: 96
Mode: MODE.EVAL
Losses: 1.1509617308902134
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.46 s

Epoch: 97
Mode: MODE.TRAIN
Losses: 0.40891313947298946
Metrics: {'Acc@1': 0.8685462}
Best Acc@1 till now: 0.8704243898391724


Epoch: 97
Mode: MODE.EVAL
Losses: 1.1477228898531313
Metrics: {'Acc@1': 0.63365847}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.96 s

Epoch: 98
Mode: MODE.TRAIN
Losses: 0.4069512081344414
Metrics: {'Acc@1': 0.8683264}
Best Acc@1 till now: 0.8704243898391724


Epoch: 98
Mode: MODE.EVAL
Losses: 1.1514618279068334
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.52 s

Epoch: 99
Mode: MODE.TRAIN
Losses: 0.407664446898586
Metrics: {'Acc@1': 0.8685262}
Best Acc@1 till now: 0.8704243898391724


Epoch: 99
Mode: MODE.EVAL
Losses: 1.1528064876225343
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.16 s

Epoch: 100
Mode: MODE.TRAIN
Losses: 0.4090094697444945
Metrics: {'Acc@1': 0.8677669}
Best Acc@1 till now: 0.8704243898391724


Epoch: 100
Mode: MODE.EVAL
Losses: 1.1477770708548796
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.33 s

Epoch: 101
Mode: MODE.TRAIN
Losses: 0.40952085722666565
Metrics: {'Acc@1': 0.8678069}
Best Acc@1 till now: 0.8704243898391724


Epoch: 101
Mode: MODE.EVAL
Losses: 1.1497172307056986
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.66 s

Epoch: 102
Mode: MODE.TRAIN
Losses: 0.40892525099198834
Metrics: {'Acc@1': 0.8683064}
Best Acc@1 till now: 0.8704243898391724


Epoch: 102
Mode: MODE.EVAL
Losses: 1.1529913844576307
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.82 s

Epoch: 103
Mode: MODE.TRAIN
Losses: 0.40953431249884387
Metrics: {'Acc@1': 0.86778694}
Best Acc@1 till now: 0.8704243898391724


Epoch: 103
Mode: MODE.EVAL
Losses: 1.1499227740962035
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.15 s

Epoch: 104
Mode: MODE.TRAIN
Losses: 0.4103090401805575
Metrics: {'Acc@1': 0.8682065}
Best Acc@1 till now: 0.8704243898391724


Epoch: 104
Mode: MODE.EVAL
Losses: 1.1512245854754357
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.08 s

Epoch: 105
Mode: MODE.TRAIN
Losses: 0.4099205896029692
Metrics: {'Acc@1': 0.86870605}
Best Acc@1 till now: 0.8704243898391724


Epoch: 105
Mode: MODE.EVAL
Losses: 1.1496313464869359
Metrics: {'Acc@1': 0.6330613}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.13 s

Epoch: 106
Mode: MODE.TRAIN
Losses: 0.4075820686872048
Metrics: {'Acc@1': 0.86966515}
Best Acc@1 till now: 0.8704243898391724


Epoch: 106
Mode: MODE.EVAL
Losses: 1.152748848981918
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.30 s

Epoch: 107
Mode: MODE.TRAIN
Losses: 0.4094175027726251
Metrics: {'Acc@1': 0.8684463}
Best Acc@1 till now: 0.8704243898391724


Epoch: 107
Mode: MODE.EVAL
Losses: 1.147667264292954
Metrics: {'Acc@1': 0.63335985}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.41 s

Epoch: 108
Mode: MODE.TRAIN
Losses: 0.4069666917557302
Metrics: {'Acc@1': 0.86866605}
Best Acc@1 till now: 0.8704243898391724


Epoch: 108
Mode: MODE.EVAL
Losses: 1.1485852583958085
Metrics: {'Acc@1': 0.63335985}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.35 s

Epoch: 109
Mode: MODE.TRAIN
Losses: 0.4087789846617547
Metrics: {'Acc@1': 0.8684263}
Best Acc@1 till now: 0.8704243898391724


Epoch: 109
Mode: MODE.EVAL
Losses: 1.1499597430229187
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.06 s

Epoch: 110
Mode: MODE.TRAIN
Losses: 0.40784044582825485
Metrics: {'Acc@1': 0.86860615}
Best Acc@1 till now: 0.8704243898391724


Epoch: 110
Mode: MODE.EVAL
Losses: 1.1515881726696233
Metrics: {'Acc@1': 0.63126993}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.22 s

Epoch: 111
Mode: MODE.TRAIN
Losses: 0.4069153557119467
Metrics: {'Acc@1': 0.870824}
Best Acc@1 till now: 0.8704243898391724

Train Metrics increased from: 0.8704243898391724 -> 0.8708239793777466

Epoch: 111
Mode: MODE.EVAL
Losses: 1.1492151595225
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.09 s

Epoch: 112
Mode: MODE.TRAIN
Losses: 0.4102949790294518
Metrics: {'Acc@1': 0.86726743}
Best Acc@1 till now: 0.8708239793777466


Epoch: 112
Mode: MODE.EVAL
Losses: 1.149767768990462
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.56 s

Epoch: 113
Mode: MODE.TRAIN
Losses: 0.4083067127467726
Metrics: {'Acc@1': 0.8673274}
Best Acc@1 till now: 0.8708239793777466


Epoch: 113
Mode: MODE.EVAL
Losses: 1.148858837640969
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.27 s

Epoch: 114
Mode: MODE.TRAIN
Losses: 0.4112808208369538
Metrics: {'Acc@1': 0.86952525}
Best Acc@1 till now: 0.8708239793777466


Epoch: 114
Mode: MODE.EVAL
Losses: 1.1506385381814022
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.30 s

Epoch: 115
Mode: MODE.TRAIN
Losses: 0.4083249185548719
Metrics: {'Acc@1': 0.8679668}
Best Acc@1 till now: 0.8708239793777466


Epoch: 115
Mode: MODE.EVAL
Losses: 1.149355149572822
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1015.08 s

Epoch: 116
Mode: MODE.TRAIN
Losses: 0.4082457875008778
Metrics: {'Acc@1': 0.86764705}
Best Acc@1 till now: 0.8708239793777466


Epoch: 116
Mode: MODE.EVAL
Losses: 1.1514940523797539
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.87 s

Epoch: 117
Mode: MODE.TRAIN
Losses: 0.4093036857597968
Metrics: {'Acc@1': 0.8688859}
Best Acc@1 till now: 0.8708239793777466


Epoch: 117
Mode: MODE.EVAL
Losses: 1.1506339402715111
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.79 s

Epoch: 118
Mode: MODE.TRAIN
Losses: 0.4093356700542638
Metrics: {'Acc@1': 0.8680267}
Best Acc@1 till now: 0.8708239793777466


Epoch: 118
Mode: MODE.EVAL
Losses: 1.1503800241051205
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.33 s

Epoch: 119
Mode: MODE.TRAIN
Losses: 0.4111318033369606
Metrics: {'Acc@1': 0.86638826}
Best Acc@1 till now: 0.8708239793777466


Epoch: 119
Mode: MODE.EVAL
Losses: 1.149364667333615
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.11 s

Epoch: 120
Mode: MODE.TRAIN
Losses: 0.410689829960656
Metrics: {'Acc@1': 0.8667679}
Best Acc@1 till now: 0.8708239793777466


Epoch: 120
Mode: MODE.EVAL
Losses: 1.1507488906763161
Metrics: {'Acc@1': 0.6321656}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.21 s

Epoch: 121
Mode: MODE.TRAIN
Losses: 0.4101153579361908
Metrics: {'Acc@1': 0.8680267}
Best Acc@1 till now: 0.8708239793777466


Epoch: 121
Mode: MODE.EVAL
Losses: 1.1522814737763374
Metrics: {'Acc@1': 0.63126993}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.35 s

Epoch: 122
Mode: MODE.TRAIN
Losses: 0.40686896449083565
Metrics: {'Acc@1': 0.86908567}
Best Acc@1 till now: 0.8708239793777466


Epoch: 122
Mode: MODE.EVAL
Losses: 1.152071002941982
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.10 s

Epoch: 123
Mode: MODE.TRAIN
Losses: 0.4087810072180865
Metrics: {'Acc@1': 0.86920553}
Best Acc@1 till now: 0.8708239793777466


Epoch: 123
Mode: MODE.EVAL
Losses: 1.1486525064820696
Metrics: {'Acc@1': 0.6330613}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.07 s

Epoch: 124
Mode: MODE.TRAIN
Losses: 0.40949237100837177
Metrics: {'Acc@1': 0.8700847}
Best Acc@1 till now: 0.8708239793777466


Epoch: 124
Mode: MODE.EVAL
Losses: 1.1546771651620318
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.58 s

Epoch: 125
Mode: MODE.TRAIN
Losses: 0.4101123351727605
Metrics: {'Acc@1': 0.86710757}
Best Acc@1 till now: 0.8708239793777466


Epoch: 125
Mode: MODE.EVAL
Losses: 1.1482861751963378
Metrics: {'Acc@1': 0.6330613}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.35 s

Epoch: 126
Mode: MODE.TRAIN
Losses: 0.41032037594358023
Metrics: {'Acc@1': 0.8678069}
Best Acc@1 till now: 0.8708239793777466


Epoch: 126
Mode: MODE.EVAL
Losses: 1.1486191495208984
Metrics: {'Acc@1': 0.6330613}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.14 s

Epoch: 127
Mode: MODE.TRAIN
Losses: 0.4085893591346643
Metrics: {'Acc@1': 0.86818653}
Best Acc@1 till now: 0.8708239793777466


Epoch: 127
Mode: MODE.EVAL
Losses: 1.1520785055342753
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.54 s

Epoch: 128
Mode: MODE.TRAIN
Losses: 0.40926307607489776
Metrics: {'Acc@1': 0.8673274}
Best Acc@1 till now: 0.8708239793777466


Epoch: 128
Mode: MODE.EVAL
Losses: 1.1517524973602051
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.52 s

Epoch: 129
Mode: MODE.TRAIN
Losses: 0.41134035553011444
Metrics: {'Acc@1': 0.8670876}
Best Acc@1 till now: 0.8708239793777466


Epoch: 129
Mode: MODE.EVAL
Losses: 1.1520635796959993
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1013.95 s

Epoch: 130
Mode: MODE.TRAIN
Losses: 0.4096724495024937
Metrics: {'Acc@1': 0.8682265}
Best Acc@1 till now: 0.8708239793777466


Epoch: 130
Mode: MODE.EVAL
Losses: 1.1492096151515936
Metrics: {'Acc@1': 0.63276273}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.19 s

Epoch: 131
Mode: MODE.TRAIN
Losses: 0.408214142750901
Metrics: {'Acc@1': 0.869745}
Best Acc@1 till now: 0.8708239793777466


Epoch: 131
Mode: MODE.EVAL
Losses: 1.150941185510842
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.64 s

Epoch: 132
Mode: MODE.TRAIN
Losses: 0.4079975069636274
Metrics: {'Acc@1': 0.8695652}
Best Acc@1 till now: 0.8708239793777466


Epoch: 132
Mode: MODE.EVAL
Losses: 1.149089984453408
Metrics: {'Acc@1': 0.6330613}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.38 s

Epoch: 133
Mode: MODE.TRAIN
Losses: 0.41002840386784595
Metrics: {'Acc@1': 0.867727}
Best Acc@1 till now: 0.8708239793777466


Epoch: 133
Mode: MODE.EVAL
Losses: 1.1511333425333545
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.46 s

Epoch: 134
Mode: MODE.TRAIN
Losses: 0.40860690216502876
Metrics: {'Acc@1': 0.8680267}
Best Acc@1 till now: 0.8708239793777466


Epoch: 134
Mode: MODE.EVAL
Losses: 1.150460355980381
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.50 s

Epoch: 135
Mode: MODE.TRAIN
Losses: 0.40792301950780935
Metrics: {'Acc@1': 0.86826646}
Best Acc@1 till now: 0.8708239793777466


Epoch: 135
Mode: MODE.EVAL
Losses: 1.1516752770751904
Metrics: {'Acc@1': 0.6324642}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.45 s

Epoch: 136
Mode: MODE.TRAIN
Losses: 0.4087414631186544
Metrics: {'Acc@1': 0.8685862}
Best Acc@1 till now: 0.8708239793777466


Epoch: 136
Mode: MODE.EVAL
Losses: 1.1516766817706405
Metrics: {'Acc@1': 0.6315685}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.18 s

Epoch: 137
Mode: MODE.TRAIN
Losses: 0.4094723876365615
Metrics: {'Acc@1': 0.86794674}
Best Acc@1 till now: 0.8708239793777466


Epoch: 137
Mode: MODE.EVAL
Losses: 1.1547257091589034
Metrics: {'Acc@1': 0.63126993}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.21 s

Epoch: 138
Mode: MODE.TRAIN
Losses: 0.4090330364263576
Metrics: {'Acc@1': 0.8693454}
Best Acc@1 till now: 0.8708239793777466


Epoch: 138
Mode: MODE.EVAL
Losses: 1.151704331492163
Metrics: {'Acc@1': 0.63186705}
Best Acc@1 till now: 0.6341560482978821

Epoch took 1014.54 s

Epoch: 139
Mode: MODE.TRAIN
Losses: 0.40824857754323185
Metrics: {'Acc@1': 0.8683863}
Best Acc@1 till now: 0.8708239793777466

************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629
Starting Broad Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 0.4065633869879996
Metrics: {'Acc@1': 0.8161365}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.8161364793777466

Epoch: 0
Mode: MODE.EVAL
Losses: 0.3490693208518302
Metrics: {'Acc@1': 0.85001993}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.8500199317932129
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629.pt
Epoch took 1014.66 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 0.34687449365778045
Metrics: {'Acc@1': 0.8485654}
Best Acc@1 till now: 0.8161364793777466

Train Metrics increased from: 0.8161364793777466 -> 0.848565399646759

Epoch: 1
Mode: MODE.EVAL
Losses: 0.3494789210284591
Metrics: {'Acc@1': 0.8485271}
Best Acc@1 till now: 0.8500199317932129

Epoch took 1016.23 s
loading saved model @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629.pt
Experiment:  vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629
Starting Fine Class Training...
Starting Train/Eval...

Epoch: 0
Mode: MODE.TRAIN
Losses: 1.8178260766941567
Metrics: {'Acc@1': 0.3258272}
Best Acc@1 till now: -1

Train Metrics increased from: -1 -> 0.3258272111415863

Epoch: 0
Mode: MODE.EVAL
Losses: 1.824834220728297
Metrics: {'Acc@1': 0.33947054}
Best Acc@1 till now: -1

Eval Metrics increased from: -1 -> 0.3394705355167389
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629.pt
Epoch took 1017.07 s

Epoch: 1
Mode: MODE.TRAIN
Losses: 1.6417145311375103
Metrics: {'Acc@1': 0.39224344}
Best Acc@1 till now: 0.3258272111415863

Train Metrics increased from: 0.3258272111415863 -> 0.3922434449195862

Epoch: 1
Mode: MODE.EVAL
Losses: 1.753561178590082
Metrics: {'Acc@1': 0.3633559}
Best Acc@1 till now: 0.3394705355167389

Eval Metrics increased from: 0.3394705355167389 -> 0.3633559048175812
Model CKPT saved at: ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629.pt
Epoch took 1017.09 s
Final Model saved @ ./checkpoints/vit-b-16-cifar10-full-train-fine-broad-separate-sgd-no-autoaug_1693543629.pt
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-alternate-30-epochs_1693557923
Starting Broad Fine Alternate Class Training...
Starting Train/Eval...
************************************************************************************************************************
ViTBasicForImageClassification(
  (embedding_layer): Sequential(
    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (1): Rearrange('b d ph pw -> b (ph pw) d')
  )
  (additional_class_tokens): ParameterList(
      (0): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 1x1x768 (GPU 0)]
  )
  (mlp_heads): ModuleList(
    (0): Linear(in_features=768, out_features=2, bias=True)
    (1): Linear(in_features=768, out_features=10, bias=True)
  )
  (positional_embedding): PositionalEmbedding1D()
  (transformer_encoder): TransformerEncoder(
    (tf_blocks): ModuleList(
      (0-11): 12 x TransformerBlock(
        (mha): MultiHeadAttention(
          (query_layer): Linear(in_features=768, out_features=768, bias=True)
          (key_layer): Linear(in_features=768, out_features=768, bias=True)
          (value_layer): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pos_wise_ff_layer): PositionWiseFeedForward(
          (pos_wise_feed_forward): Sequential(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (final_layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Experiment:  vit-b-16-cifar10-full-train-fine-broad-alternate-30-epochs_1693558155
Starting Broad Fine Alternate Class Training...
Starting Train/Eval...
